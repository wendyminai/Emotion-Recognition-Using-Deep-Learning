{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f023995",
   "metadata": {},
   "source": [
    "# Evaluate AffectNet March2021\n",
    "* Author: Sungguk Cha\n",
    "* eMail: sungguk@ncsoft.com\n",
    "* Date: 4th Nov. 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd3275",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "411264c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 1.12.1\n",
      "Timm: 0.6.11\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet101, mobilenet_v2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from robust_optimization import RobustOptimizer\n",
    "\n",
    "print(f'Torch: {torch.__version__}')\n",
    "print(f'Timm: {timm.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8a8407",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4192fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "affectnet_dir = '../../../../datasets/affectnet'\n",
    "USE_ENET2=False #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90dfe4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "batch_size = 32 #48# 32# 32 #16 #8 #\n",
    "epochs = 40\n",
    "lr = 3e-5\n",
    "gamma = 0.7\n",
    "seed = 42\n",
    "device = 'cuda'\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6dcec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE=260 if USE_ENET2 else 224 # 300 # 80 #\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "print(test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d96c366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 0, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af7d729",
   "metadata": {},
   "source": [
    "## AffectNet Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "363e8e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference https://github.com/yaoing/DAN/blob/main/affectnet.py\n",
    "# phase: one of ['train', 'val']\n",
    "class AffectNet(data.Dataset):\n",
    "    def __init__(self, aff_path, phase, use_cache=True, transforms=None, force=False):\n",
    "        self.phase = phase\n",
    "        self.transforms = transforms\n",
    "        self.aff_path = aff_path\n",
    "        self.base_path = os.path.join(self.aff_path, f'{self.phase}_set/')\n",
    "        \n",
    "        if use_cache:\n",
    "            cache_path = os.path.join(aff_path,f'affectnet_{phase}.csv')\n",
    "            if os.path.exists(cache_path) and not force:\n",
    "                df = pd.read_csv(cache_path)\n",
    "            else:\n",
    "                df = self.get_df()\n",
    "                df.to_csv(cache_path)\n",
    "        else:\n",
    "            df = self.get_df()\n",
    "\n",
    "        self.data = df[df['phase'] == phase]\n",
    "\n",
    "        self.file_paths = self.data.loc[:, 'img_path'].values\n",
    "        self.label = self.data.loc[:, 'label'].values\n",
    "\n",
    "        self.emotion_labels=['Neutral','Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt']\n",
    "        sample_label, sample_counts = np.unique(self.label, return_counts=True)\n",
    "        for l, c in zip(sample_label, sample_counts):\n",
    "            print(f'{self.emotion_labels[l]}: {c} ', end='')\n",
    "        print(f'\\n{len(self)} images')\n",
    "\n",
    "    def get_df(self):\n",
    "        base_path = os.path.join(self.aff_path, f'{self.phase}_set/')\n",
    "        self.base_path = base_path\n",
    "        data = []\n",
    "        \n",
    "        for anno in glob.glob(base_path + 'annotations/*_exp.npy'):\n",
    "            idx = os.path.basename(anno).split('_')[0]\n",
    "            img_path = f'images/{idx}.jpg'\n",
    "            label = int(np.load(anno))\n",
    "            data.append([self.phase,img_path,label])\n",
    "        \n",
    "        return pd.DataFrame(data = data,columns = ['phase','img_path','label'])\n",
    "    \n",
    "    def get_weight(self):\n",
    "        self.emotion_labels=['Neutral','Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt']\n",
    "        self.class_to_idx = {}\n",
    "        self.idx_to_class = {}\n",
    "        for i, emotion in enumerate(self.emotion_labels):\n",
    "            self.class_to_idx[emotion] = i\n",
    "            self.idx_to_class[i] = emotion\n",
    "        sample_label, sample_counts = np.unique(self.label, return_counts=True)\n",
    "        for l, c in zip(sample_label, sample_counts):\n",
    "            print(f'{self.emotion_labels[l]}: {c} ', end='')\n",
    "        print('')\n",
    "        \n",
    "        cw = 1/sample_counts\n",
    "        cw /= cw.min()\n",
    "        class_weights = {i:cwi for i, cwi in zip(sample_label, cw)}\n",
    "        print(class_weights)\n",
    "        return class_weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = os.path.join(self.base_path, self.file_paths[idx])\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        label = self.label[idx]\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a09579cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral: 74874 Happiness: 134415 Sadness: 25459 Surprise: 14090 Fear: 6378 Disgust: 3803 Anger: 24882 Contempt: 3750 \n",
      "287651 images\n",
      "Neutral: 500 Happiness: 500 Sadness: 500 Surprise: 500 Fear: 500 Disgust: 500 Anger: 500 Contempt: 499 \n",
      "3999 images\n"
     ]
    }
   ],
   "source": [
    "trainset = AffectNet(affectnet_dir, 'train', transforms=train_transforms, force=False)\n",
    "valset = AffectNet(affectnet_dir, 'val', transforms=test_transforms, force=False)\n",
    "trainloader = data.DataLoader(trainset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "valloader = data.DataLoader(valset, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cd4f957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral: 74874 Happiness: 134415 Sadness: 25459 Surprise: 14090 Fear: 6378 Disgust: 3803 Anger: 24882 Contempt: 3750 \n",
      "{0: 1.7952159628175335, 1: 1.0, 2: 5.279665344279037, 3: 9.539744499645138, 4: 21.07478833490122, 5: 35.34446489613463, 6: 5.402097902097902, 7: 35.844}\n"
     ]
    }
   ],
   "source": [
    "class_weights = trainset.get_weight()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212fb636",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ba12a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "def set_parameter_requires_grad(model, requires_grad):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c1979cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "weights = torch.FloatTensor(list(class_weights.values())).cuda()\n",
    "\n",
    "def label_smooth(target, n_classes: int, label_smoothing=0.1):\n",
    "    # convert to one-hot\n",
    "    batch_size = target.size(0)\n",
    "    target = torch.unsqueeze(target, 1)\n",
    "    soft_target = torch.zeros((batch_size, n_classes), device=target.device)\n",
    "    soft_target.scatter_(1, target, 1)\n",
    "    # label smoothing\n",
    "    soft_target = soft_target * (1 - label_smoothing) + label_smoothing / n_classes\n",
    "    return soft_target\n",
    "\n",
    "def cross_entropy_loss_with_soft_target(pred, soft_target):\n",
    "    #logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "    return torch.mean(torch.sum(- weights*soft_target * torch.nn.functional.log_softmax(pred, -1), 1))\n",
    "\n",
    "def cross_entropy_with_label_smoothing(pred, target):\n",
    "    soft_target = label_smooth(target, pred.size(1)) #num_classes) #\n",
    "    return cross_entropy_loss_with_soft_target(pred, soft_target)\n",
    "\n",
    "criterion=cross_entropy_with_label_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efe6b6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('EfficientNet_b0_best_afew', '../../models/affectnet_emotions/enet_b0_8_best_afew.pt'))\n",
    "models.append(('EfficientNet_b0_best_vgaf', '../../models/affectnet_emotions/enet_b0_8_best_vgaf.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d8aa4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Neutral': 0, 'Happiness': 1, 'Sadness': 2, 'Surprise': 3, 'Fear': 4, 'Disgust': 5, 'Anger': 6, 'Contempt': 7}\n",
      "{0: 'Neutral', 1: 'Happiness', 2: 'Sadness', 3: 'Surprise', 4: 'Fear', 5: 'Disgust', 6: 'Anger', 7: 'Contempt'}\n"
     ]
    }
   ],
   "source": [
    "class_to_idx = trainset.class_to_idx\n",
    "print(class_to_idx)\n",
    "idx_to_class = trainset.idx_to_class\n",
    "print(idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b6076af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 6, 1: 7, 2: 5, 3: 4, 4: 1, 5: 0, 6: 2, 7: 3}\n"
     ]
    }
   ],
   "source": [
    "pretrained_8 = {0: 'Anger', 1: 'Contempt', 2: 'Disgust', 3: 'Fear', 4: 'Happiness', 5: 'Neutral', 6: 'Sadness', 7: 'Surprise'}\n",
    "new_order_8 = ['Neutral','Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt']\n",
    "new_order_8 = {k: new_order_8.index(v) for k, v in pretrained_8.items()}\n",
    "print(new_order_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d24ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_pretrained(model, length, dataloader, criterion):\n",
    "    pretrained_8 = {0: 'Anger', 1: 'Contempt', 2: 'Disgust', 3: 'Fear', 4: 'Happiness', 5: 'Neutral', 6: 'Sadness', 7: 'Surprise'}\n",
    "    new_order_8 = ['Neutral','Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger', 'Contempt']\n",
    "    new_order_8 = {k: new_order_8.index(v) for k, v in pretrained_8.items()}\n",
    "    new_order = new_order_8\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    for (images, emotions) in tqdm(dataloader):\n",
    "        images = images.cuda()\n",
    "        emotions = emotions\n",
    "        preds = model(images)\n",
    "        # loss\n",
    "        # loss += criterion(preds, emotions)\n",
    "        # accuracy\n",
    "        preds = torch.argmax(preds, dim=1).cpu()\n",
    "        preds = preds.apply_(new_order.get)\n",
    "        acc = torch.eq(preds, emotions).sum()\n",
    "        accuracy += acc\n",
    "    loss /= length\n",
    "    accuracy /= length\n",
    "    print(f'Accuracy: {accuracy}, Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c585a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_pretrained_7(model, length, dataloader, criterion):\n",
    "    pretrained_8 = {0: 'Anger', 1: 'Disgust', 2: 'Fear', 3: 'Happiness', 4: 'Neutral', 5: 'Sadness', 6: 'Surprise'}\n",
    "    new_order_8 = ['Neutral','Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger']\n",
    "    new_order_8 = {k: new_order_8.index(v) for k, v in pretrained_8.items()}\n",
    "    new_order = new_order_8\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    for (images, emotions) in tqdm(dataloader):\n",
    "        images = images.cuda()\n",
    "        emotions = emotions\n",
    "        preds = model(images)\n",
    "        # loss\n",
    "        # loss += criterion(preds, emotions)\n",
    "        # accuracy\n",
    "        preds = torch.concat([preds[:, 0:1], preds[:, 2:]], dim=1)\n",
    "        preds = torch.argmax(preds, dim=1).cpu()\n",
    "        preds = preds.apply_(new_order.get)\n",
    "        acc = torch.eq(preds, emotions).sum()\n",
    "        accuracy += acc\n",
    "    loss /= length\n",
    "    accuracy /= (length-499)\n",
    "    print(f'Accuracy: {accuracy}, Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "683f3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, valloader):    \n",
    "    model = torch.load(model)\n",
    "    model = model.eval().cuda()\n",
    "    eval_pretrained(model, len(valset), valloader, criterion=None)\n",
    "    eval_pretrained_7(model, len(valset), valloader, criterion=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77dab694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet_b0_best_afew\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2982073f222347faa18bd00948bfa596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5956488847732544, Loss: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a899ae3db04f93988333c70b9fe61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6394285559654236, Loss: 0.0\n",
      "EfficientNet_b0_best_vgaf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d0ff30c39e41dfb048b41e98496545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6071518063545227, Loss: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1158fd0cfd9417d9914cbdb0e63bc1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6422857046127319, Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "    print(name)\n",
    "    test(model, valloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
