{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "DATA_DIR = pathlib.Path('/home/HDD6TB/datasets/emotions/ABAW/eccv_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn import svm,metrics,preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score,roc_auc_score,average_precision_score\n",
    "import mord\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv  \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_transfer(label,class_num):\n",
    "    return np.eye(class_num)[label]\n",
    "\n",
    "def metric_for_Exp(gt,pred,class_num=8):\n",
    "    # compute_acc\n",
    "    acc = accuracy_score(gt,pred)\n",
    "    # compute_F1\n",
    "    gt = one_hot_transfer(gt,class_num)\n",
    "    pred = one_hot_transfer(pred,class_num)\n",
    "    F1 = []\n",
    "    for i in range(class_num):\n",
    "        gt_ = gt[:,i]\n",
    "        pred_ = pred[:,i]\n",
    "        F1.append(f1_score(gt_.flatten(), pred_))\n",
    "    F1_mean = np.mean(F1)\n",
    "    return F1_mean,acc,F1\n",
    "\n",
    "def CCC_score(x, y):\n",
    "    vx = x - np.mean(x)\n",
    "    vy = y - np.mean(y)\n",
    "    rho = np.sum(vx * vy) / (np.sqrt(np.sum(vx**2)) * np.sqrt(np.sum(vy**2)))\n",
    "    x_m = np.mean(x)\n",
    "    y_m = np.mean(y)\n",
    "    x_s = np.std(x)\n",
    "    y_s = np.std(y)\n",
    "    ccc = 2*rho*x_s*y_s/(x_s**2 + y_s**2 + (x_m - y_m)**2)\n",
    "    return ccc\n",
    "\n",
    "def metric_for_VA(gt_V,gt_A,pred_V,pred_A):\n",
    "    ccc_V,ccc_A = CCC_score(gt_V,pred_V),CCC_score(gt_A,pred_A)\n",
    "    return ccc_V,ccc_A, 0.5*(ccc_V+ccc_A)\n",
    "\n",
    "def CCC_numpy(y_true, y_pred):\n",
    "    '''Reference numpy implementation of Lin's Concordance correlation coefficient'''\n",
    "    \n",
    "    # covariance between y_true and y_pred\n",
    "    s_xy = np.cov([y_true, y_pred])[0,1]\n",
    "    # means\n",
    "    x_m = np.mean(y_true)\n",
    "    y_m = np.mean(y_pred)\n",
    "    # variances\n",
    "    s_x_sq = np.var(y_true)\n",
    "    s_y_sq = np.var(y_pred)\n",
    "    \n",
    "    # condordance correlation coefficient\n",
    "    ccc = (2.0*s_xy) / (s_x_sq + s_y_sq + (x_m-y_m)**2)\n",
    "    \n",
    "    return ccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_filenames=lambda x: int(os.path.splitext(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.layers import TimeDistributed, GRU, Dense, Dropout, Flatten, LSTM, Activation, MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2 as L2_reg\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, \\\n",
    "    MaxPool2D, GlobalMaxPool2D, Input, Masking, Conv3D, MaxPooling3D, GlobalMaxPool3D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import tensorflow.keras.backend as K \n",
    "from tensorflow.keras.models import load_model,Model\n",
    "\n",
    "print(tf.__version__)\n",
    "from tensorflow.compat.v1.keras.backend import set_session \n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess=tf.compat.v1.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 1.7.1+cu110\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(f\"Torch: {torch.__version__}\")\n",
    "device = 'cuda'\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_classes=7\n",
    "if False:\n",
    "    #PATH='affectnet_vggface2_enet2_gmp_smooth.pt'\n",
    "    PATH='enet_b2_8.pt'\n",
    "    #PATH='enet_b2_7.pt'\n",
    "    IMG_SIZE=260 #224 #\n",
    "else:\n",
    "    #PATH='affectnet_vggface2_enet0.pt'\n",
    "    #PATH='affectnet_vggface2_enet0_new.pt'\n",
    "    #PATH='enet_b0_7.pt'\n",
    "    #PATH='enet_b0_8_best_afew.pt'\n",
    "    \n",
    "    #PATH='enet_b0_8_best_vgaf.pt'\n",
    "    PATH='enet_b0_8_va_mtl.pt'\n",
    "    IMG_SIZE=224\n",
    "    \n",
    "#IMG_SIZE=112\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "np_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(None),\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_va_mtl.pt\n"
     ]
    }
   ],
   "source": [
    "print(PATH)\n",
    "feature_extractor_model = torch.load('../../models/affectnet_emotions/'+PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1280) [[ 0.00679121  0.09001139  0.0694934  ...  0.10351563 -0.00995514\n",
      "  -0.17376047]\n",
      " [-0.004085   -0.07134113 -0.12164655 ... -0.05029012  0.03059323\n",
      "   0.08198261]\n",
      " [-0.0034241  -0.06510569 -0.00448079 ...  0.04248156 -0.10535879\n",
      "  -0.00544419]\n",
      " ...\n",
      " [ 0.07878461 -0.03540913 -0.06665969 ... -0.10314589  0.1332206\n",
      "  -0.06119434]\n",
      " [-0.02409821 -0.00270485  0.00887998 ... -0.00501176  0.01345664\n",
      "  -0.02131553]\n",
      " [-0.04529824 -0.04590099 -0.00950194 ...  0.00753843  0.02128105\n",
      "  -0.05743075]]\n",
      "(10,) [-0.03629377 -0.00268708 -0.05411524  0.01482256  0.13788255  0.09921926\n",
      " -0.05259513 -0.0124341   0.0816549   0.04621203]\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    classifier_weights=feature_extractor_model.classifier[0].weight.cpu().data.numpy()\n",
    "    classifier_bias=feature_extractor_model.classifier[0].bias.cpu().data.numpy()\n",
    "else:\n",
    "    classifier_weights=feature_extractor_model.classifier.weight.cpu().data.numpy()\n",
    "    classifier_bias=feature_extractor_model.classifier.bias.cpu().data.numpy()\n",
    "print(classifier_weights.shape,classifier_weights)\n",
    "print(classifier_bias.shape,classifier_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): SiLU(inplace=True)\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "        (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(144, 144, kernel_size=(5, 5), stride=(2, 2), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(240, 240, kernel_size=(3, 3), stride=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(672, 672, kernel_size=(5, 5), stride=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): SiLU(inplace=True)\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "  (classifier): Identity()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor_model.classifier=torch.nn.Identity()\n",
    "feature_extractor_model=feature_extractor_model.to(device)\n",
    "feature_extractor_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probab(features, logits=True):\n",
    "    x=np.dot(features,np.transpose(classifier_weights))+classifier_bias\n",
    "    if logits:\n",
    "        return x\n",
    "    #print(x)\n",
    "    e_x = np.exp(x - np.max(x,axis=1)[:,np.newaxis])\n",
    "    #print(x.shape,x,np.max(x,axis=1),e_x)\n",
    "    return e_x / e_x.sum(axis=1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "/home/HDD6TB/datasets/emotions/ABAW/eccv_4/SR/cropped_aligned\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69ba1868dc04aef883f9aa125f8951f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(test_transforms)\n",
    "#data_dir=DATA_DIR / 'cropped'\n",
    "\n",
    "data_dir=DATA_DIR / 'cropped_aligned'\n",
    "#data_dir=DATA_DIR / 'SR/cropped_aligned'\n",
    "print(data_dir)\n",
    "img_names=[]\n",
    "X_global_features=[]\n",
    "imgs=[]\n",
    "for filename in tqdm(os.listdir(data_dir)):\n",
    "    frames_dir=data_dir / filename \n",
    "    for img_name in os.listdir(frames_dir):\n",
    "        if img_name.lower().endswith('.jpg'):\n",
    "            img = Image.open(data_dir /filename / img_name)\n",
    "            img_tensor = test_transforms(img)\n",
    "            if img.size:\n",
    "                img_names.append(filename+'/'+img_name)\n",
    "                imgs.append(img_tensor)\n",
    "                if len(imgs)>=64: #96: #48: #32:        \n",
    "                    features = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "                    features=features.data.cpu().numpy()\n",
    "                    #print(features.shape)\n",
    "\n",
    "                    if len(X_global_features)==0:\n",
    "                        X_global_features=features\n",
    "                    else:\n",
    "                        X_global_features=np.concatenate((X_global_features,features),axis=0)\n",
    "                    imgs=[]\n",
    "\n",
    "if len(imgs)>0:        \n",
    "    features = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "    features=features.data.cpu().numpy()\n",
    "\n",
    "    if len(X_global_features)==0:\n",
    "        X_global_features=features\n",
    "    else:\n",
    "        X_global_features=np.concatenate((X_global_features,features),axis=0)\n",
    "\n",
    "    imgs=[]\n",
    "\n",
    "    #X_scores=X_global_features #get_probab(X_global_features)\n",
    "    #print(X_global_features.shape,X_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.8688838e+00 -1.2798675e+00  4.0342087e-01 -1.9031891e+00\n",
      "  -3.6277884e-01  2.7075288e+00 -4.8229852e-01  1.6048644e+00\n",
      "  -1.4294155e-02  2.8019422e-01]\n",
      " [-1.3015268e+00 -3.5388476e-01 -3.5591192e+00 -7.4799877e-01\n",
      "   1.4669149e+00  4.0818615e+00 -3.0371362e-01  3.3040609e+00\n",
      "   1.3480158e-01 -1.0034430e-01]\n",
      " [-5.5128229e-01  4.1866582e-04 -2.1932106e+00 -1.8251675e+00\n",
      "   3.1605902e+00  2.8578134e+00 -1.9422179e+00  2.0182512e+00\n",
      "   4.4615337e-01 -5.6445170e-02]\n",
      " [-4.1735449e-01 -1.7355011e+00 -2.4780661e-01 -1.4196098e-01\n",
      "   2.2339792e+00  8.8991779e-01 -3.8366860e-01  1.1287602e+00\n",
      "   4.1341019e-01  2.0222169e-01]\n",
      " [ 9.8042774e-01 -3.6756520e+00 -1.9611456e+00  1.1986889e+00\n",
      "   1.6967728e+00  5.7321155e-01 -1.0199708e+00  3.3609467e+00\n",
      "   3.7330532e-01  5.6045234e-01]]\n"
     ]
    }
   ],
   "source": [
    "X_scores=get_probab(X_global_features,logits=True)\n",
    "print(X_scores[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168097\n"
     ]
    }
   ],
   "source": [
    "filename2featuresAll={img_name:(global_features,scores) for img_name,global_features,scores in zip(img_names,X_global_features,X_scores)}\n",
    "#filename2featuresAll={img_name:(global_features,) for img_name,global_features, in zip(img_names,X_global_features)}\n",
    "print(len(filename2featuresAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "/home/HDD6TB/datasets/emotions/ABAW/eccv_4/mtl_test_data/cropped_aligned\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890b81a4eae24f079e0ed792d05be923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(test_transforms)\n",
    "data_dir=DATA_DIR / 'mtl_test_data/cropped_aligned'\n",
    "print(data_dir)\n",
    "img_names=[]\n",
    "X_global_features=[]\n",
    "imgs=[]\n",
    "for filename in tqdm(os.listdir(data_dir)):\n",
    "    frames_dir=data_dir / filename \n",
    "    for img_name in os.listdir(frames_dir):\n",
    "        if img_name.lower().endswith('.jpg'):\n",
    "            img = Image.open(data_dir /filename / img_name)\n",
    "            img_tensor = test_transforms(img)\n",
    "            if img.size:\n",
    "                img_names.append(filename+'/'+img_name)\n",
    "                imgs.append(img_tensor)\n",
    "                if len(imgs)>=64: #96: #48: #32:        \n",
    "                    features = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "                    features=features.data.cpu().numpy()\n",
    "                    #print(features.shape)\n",
    "\n",
    "                    if len(X_global_features)==0:\n",
    "                        X_global_features=features\n",
    "                    else:\n",
    "                        X_global_features=np.concatenate((X_global_features,features),axis=0)\n",
    "                    imgs=[]\n",
    "\n",
    "if len(imgs)>0:        \n",
    "    features = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "    features=features.data.cpu().numpy()\n",
    "\n",
    "    if len(X_global_features)==0:\n",
    "        X_global_features=features\n",
    "    else:\n",
    "        X_global_features=np.concatenate((X_global_features,features),axis=0)\n",
    "\n",
    "    imgs=[]\n",
    "\n",
    "    #X_scores=X_global_features #get_probab(X_global_features)\n",
    "    #print(X_global_features.shape,X_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.2368399e+00  1.3957083e+00 -2.1751339e+00 -2.6532381e+00\n",
      "   3.7151897e+00  2.1231325e+00 -1.2529771e+00  1.8865112e+00\n",
      "   6.5451306e-01 -1.1197664e-03]\n",
      " [-4.5890012e-01  1.7170735e-01 -2.1290927e+00 -1.3519958e+00\n",
      "   2.0608756e-01  2.9360936e+00  9.5479238e-01  3.2599382e+00\n",
      "   6.9401488e-03 -3.6578562e-02]\n",
      " [-9.2518651e-01 -1.5683583e+00 -1.1122453e+00  1.2513974e+00\n",
      "   9.5606560e-01  1.4045405e+00 -1.0135034e+00  4.0808926e+00\n",
      "   2.7149817e-01  4.7487086e-01]\n",
      " [-6.6330218e-01  3.7657097e-01 -7.0575130e-01 -3.1108387e+00\n",
      "   2.9681218e+00  3.2157569e+00  3.4092167e-01  5.1639426e-01\n",
      "   4.2772499e-01 -1.6744725e-01]\n",
      " [-1.8718929e+00  2.6364112e+00 -2.2357848e+00 -4.3089094e+00\n",
      "   4.6268377e+00  2.8123999e+00 -1.0999391e+00  6.6852532e-02\n",
      "   7.0621473e-01 -1.4183587e-01]]\n"
     ]
    }
   ],
   "source": [
    "X_scores=get_probab(X_global_features,logits=True)\n",
    "print(X_scores[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50441\n"
     ]
    }
   ],
   "source": [
    "filename2featuresTest={img_name:(global_features,scores) for img_name,global_features,scores in zip(img_names,X_global_features,X_scores)}\n",
    "print(len(filename2featuresTest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('enet_b0_8_va_mtl_aligned_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(filename2featuresTest, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/load features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../emotions-multimodal/faces/ABAW/abaw4/enet_b0_8_va_mtl_aligned.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "if False:\n",
    "    model_name='mymobilenet_7_ft_sgd_model'\n",
    "    num_classes=7\n",
    "else:\n",
    "    #model_name='enet0_8'\n",
    "    num_classes=8\n",
    "    #model_name='enet0_7'\n",
    "    #model_name='enet_b0_8_best_afew'\n",
    "    #model_name='enet_b0_8_best_vgaf' #first three challenges\n",
    "    #model_name='enet2_8' #MTL challenge\n",
    "    #model_name='enet2_7'\n",
    "    model_name='enet_b0_8_va_mtl' \n",
    "\n",
    "model_name+='_aligned'#'_SR' #\n",
    "#MODEL2FEATURES=model_name+'_aligned.pickle'\n",
    "MODEL2FEATURES=model_name+'.pickle' \n",
    "\n",
    "MODEL2FEATURES='../../../emotions-multimodal/faces/ABAW/abaw4/'+MODEL2FEATURES\n",
    "\n",
    "print(MODEL2FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(MODEL2FEATURES, 'wb') as handle:\n",
    "        pickle.dump(filename2featuresAll, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168097\n"
     ]
    }
   ],
   "source": [
    "with open(MODEL2FEATURES, 'rb') as handle:\n",
    "    filename2featuresAll=pickle.load(handle)\n",
    "print(len(filename2featuresAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50441\n"
     ]
    }
   ],
   "source": [
    "with open('enet_b0_8_va_mtl_aligned_test.pickle', 'rb') as handle:\n",
    "    filename2featuresTest=pickle.load(handle)\n",
    "print(len(filename2featuresTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model,Sequential, load_model,model_from_json\n",
    "from tensorflow.keras.applications import mobilenet,mobilenet_v2,densenet,inception_resnet_v2,inception_v3,vgg16,resnet_v2,resnet\n",
    "#from tensorflow.keras.applications import efficientnet as enet\n",
    "import efficientnet.tfkeras as enet\n",
    "#from tensorflow.keras.utils.generic_utils import CustomObjectScope\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout,GlobalAveragePooling2D,Activation, Conv2D, Reshape,DepthwiseConv2D,Input\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, Callback, CSVLogger, EarlyStopping\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_best_metric='val_loss', this_max=False):\n",
    "        self.save_best_metric = save_best_metric\n",
    "        self.max = this_max\n",
    "        if this_max:\n",
    "            self.best = float('-inf')\n",
    "        else:\n",
    "            self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric_value = logs[self.save_best_metric]\n",
    "        if self.max:\n",
    "            if metric_value > self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_model_weights = deepcopy(self.model.get_weights())\n",
    "\n",
    "        else:\n",
    "            if metric_value < self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_model_weights = deepcopy(self.model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCC(y_true, y_pred):\n",
    "    '''Lin's Concordance correlation coefficient: https://en.wikipedia.org/wiki/Concordance_correlation_coefficient\n",
    "    \n",
    "    The concordance correlation coefficient is the correlation between two variables that fall on the 45 degree line through the origin.\n",
    "    \n",
    "    It is a product of\n",
    "    - precision (Pearson correlation coefficient) and\n",
    "    - accuracy (closeness to 45 degree line)\n",
    "\n",
    "    Interpretation:\n",
    "    - `rho_c =  1` : perfect agreement\n",
    "    - `rho_c =  0` : no agreement\n",
    "    - `rho_c = -1` : perfect disagreement \n",
    "    \n",
    "    Args: \n",
    "    - y_true: ground truth\n",
    "    - y_pred: predicted values\n",
    "    \n",
    "    Returns:\n",
    "    - concordance correlation coefficient (float)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # covariance between y_true and y_pred\n",
    "    #N = K.int_shape(y_pred)[-1]\n",
    "    #s_xy = 1.0 / (N - 1.0 + K.epsilon()) * K.sum((y_true - K.mean(y_true)) * (y_pred - K.mean(y_pred)))\n",
    "    #s_xy = K.mean(K.sum((y_true - K.mean(y_true)) * (y_pred - K.mean(y_pred))))\n",
    "    s_xy = K.mean((y_true - K.mean(y_true)) * (y_pred - K.mean(y_pred)))\n",
    "    # means\n",
    "    x_m = K.mean(y_true)\n",
    "    y_m = K.mean(y_pred)\n",
    "    # variances\n",
    "    s_x_sq = K.var(y_true)\n",
    "    s_y_sq = K.var(y_pred)\n",
    "    \n",
    "    # condordance correlation coefficient\n",
    "    ccc = (2.0*s_xy) / (s_x_sq + s_y_sq + (x_m-y_m)**2+K.epsilon())\n",
    "    #print(s_xy,s_x_sq,s_y_sq,x_m,y_m)\n",
    "    return ccc\n",
    "\n",
    "def CCC_VA(y_true, y_pred):\n",
    "    return 1-0.5*(CCC(y_true[:,0], y_pred[:,0])+CCC(y_true[:,1], y_pred[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def f1_score_max_for_AU_one_class(gt, pred, thresh,type=0):\n",
    "    gt = gt[:,type]\n",
    "    pred = pred[:,type]\n",
    "    P = []\n",
    "    R = []\n",
    "    ACC = []\n",
    "    F1 = []\n",
    "    for i in thresh:\n",
    "        new_pred = ((pred >= i) * 1).flatten()\n",
    "        P.append(precision_score(gt.flatten(), new_pred))\n",
    "        R.append(recall_score(gt.flatten(), new_pred))\n",
    "        ACC.append(accuracy_score(gt.flatten(), new_pred))\n",
    "        F1.append(f1_score(gt.flatten(), new_pred))\n",
    "\n",
    "    F1_MAX = max(F1)\n",
    "    if F1_MAX < 0 or math.isnan(F1_MAX):\n",
    "        F1_MAX = 0\n",
    "        F1_THRESH = 0\n",
    "        accuracy = 0\n",
    "    else:\n",
    "        idx_thresh = np.argmax(F1)\n",
    "        F1_THRESH = thresh[idx_thresh]\n",
    "        accuracy = ACC[idx_thresh]\n",
    "    return F1,F1_MAX,F1_THRESH,accuracy\n",
    "\n",
    "def f1_score_max(gt, pred, thresh,c=12):\n",
    "    F1_s = []\n",
    "    F1_t = []\n",
    "    ACC = []\n",
    "    from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "    for i in range(c):\n",
    "        F1, F1_MAX, F1_THRESH,acc = f1_score_max_for_AU_one_class(gt,pred,thresh,i)\n",
    "        F1_s.append(F1_MAX)\n",
    "        F1_t.append(F1_THRESH)\n",
    "        ACC.append(acc)\n",
    "    F1_s=np.array(F1_s)\n",
    "    F1_t=np.array(F1_t)\n",
    "    ACC=np.array(ACC)\n",
    "    return F1_s.mean(),F1_t.mean(),F1_s,F1_t,ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-task challenge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142333, 1290) (142333, 2) (142333,) (142333, 12) (142333,) 0\n",
      "(26876, 1290) (26876, 2) (26876,) (26876, 12) (26876,) 0\n"
     ]
    }
   ],
   "source": [
    "FEATURES_ONLY,SCORES_ONLY,FEATURES_SCORES=0,1,2\n",
    "FEATURES_SCORES_AGGREGATION=FEATURES_SCORES\n",
    "def get_image2all(filename):\n",
    "    with open(DATA_DIR / filename) as f:\n",
    "        mtl_lines = f.read().splitlines()\n",
    "    num_missed=0\n",
    "    X,y_va,y_expr,y_aus=[],[],[],[]\n",
    "    masks_va,masks_expr,masks_aus=[],[],[]\n",
    "    for line in mtl_lines[1:]:\n",
    "        splitted_line=line.split(',')\n",
    "        imagename=splitted_line[0]\n",
    "        valence=float(splitted_line[1])\n",
    "        arousal=float(splitted_line[2])\n",
    "        expression=int(splitted_line[3])\n",
    "        aus=list(map(int,splitted_line[4:]))\n",
    "        \n",
    "        if False:\n",
    "            imagename=imagename[:-4]+'_out.jpg'\n",
    "            #print(imagename)\n",
    "        \n",
    "        mask_VA=(valence>-5 and arousal>-5)\n",
    "        if not mask_VA:\n",
    "            valence=arousal=0\n",
    "            \n",
    "        mask_expr=(expression>-1)\n",
    "        if not mask_expr:\n",
    "            expression=0\n",
    "            \n",
    "        mask_aus=min(aus)>=0\n",
    "        if not mask_aus:\n",
    "            aus=[0]*len(aus)\n",
    "        #print(imagename,valence,arousal,expression,aus)\n",
    "        if mask_VA or mask_expr or mask_aus:\n",
    "            if imagename in filename2featuresAll:\n",
    "                if FEATURES_SCORES_AGGREGATION==FEATURES_ONLY:\n",
    "                    X.append(filename2featuresAll[imagename][0])\n",
    "                elif FEATURES_SCORES_AGGREGATION==SCORES_ONLY:\n",
    "                    X.append(filename2featuresAll[imagename][1])\n",
    "                else:\n",
    "                    X.append(np.concatenate((filename2featuresAll[imagename][0],filename2featuresAll[imagename][1])))\n",
    "                y_va.append((valence,arousal))\n",
    "                masks_va.append(mask_VA)\n",
    "                \n",
    "                y_expr.append(expression)\n",
    "                masks_expr.append(mask_expr)\n",
    "                \n",
    "                y_aus.append(aus)\n",
    "                masks_aus.append(mask_aus)\n",
    "            else:\n",
    "                num_missed+=1\n",
    "        #elif (valence==-5 or arousal==-5) and valence!=arousal:\n",
    "        #    print(valence,arousal)\n",
    "    X=np.array(X)\n",
    "    y_va=np.array(y_va)\n",
    "    y_expr=np.array(y_expr)\n",
    "    y_aus=np.array(y_aus)\n",
    "    masks_va=np.array(masks_va).astype(np.float32)\n",
    "    masks_expr=np.array(masks_expr).astype(np.float32)\n",
    "    masks_aus=np.array(masks_aus).astype(np.float32)\n",
    "    print(X.shape,y_va.shape,y_expr.shape,y_aus.shape,masks_va.shape,num_missed)\n",
    "    return X,y_va,y_expr,y_aus,masks_va,masks_expr,masks_aus\n",
    "\n",
    "X_train,y_va_train,y_expr_train,y_aus_train,masks_va_train,masks_expr_train,masks_aus_train=get_image2all('training_set_annotations.txt')\n",
    "X_val,y_va_val,y_expr_val,y_aus_val,masks_va_val,masks_expr_val,masks_aus_val=get_image2all('validation_set_annotations.txt')\n",
    "TRAIN_VAL=False\n",
    "\n",
    "#cropped: (142333, 1288) (142333, 2) (142333,) (142333, 12) (142333,) 0\n",
    "#(26876, 1288) (26876, 2) (26876,) (26876, 12) (26876,) 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    def softmax(x):\n",
    "        e_x = np.exp(x - np.max(x,axis=1)[:,np.newaxis])\n",
    "        return e_x / e_x.sum(axis=1)[:,None]\n",
    "    X_train=softmax(X_train)\n",
    "    print(X_train.shape,X_train[:5])\n",
    "    X_val=softmax(X_val)\n",
    "    print(X_val.shape,X_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169209, 1290) (169209, 2) (169209,) (169209, 12) (169209,) (169209,) (169209,)\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    TRAIN_VAL=True\n",
    "    X_train=np.concatenate((X_train,X_val))\n",
    "    y_va_train=np.concatenate((y_va_train,y_va_val))\n",
    "    y_expr_train=np.concatenate((y_expr_train,y_expr_val))\n",
    "    y_aus_train=np.concatenate((y_aus_train,y_aus_val))\n",
    "    masks_va_train=np.concatenate((masks_va_train,masks_va_val))\n",
    "    masks_expr_train=np.concatenate((masks_expr_train,masks_expr_val))\n",
    "    masks_aus_train=np.concatenate((masks_aus_train,masks_aus_val))\n",
    "    print(X_train.shape,y_va_train.shape,y_expr_train.shape,y_aus_train.shape,\n",
    "          masks_va_train.shape,masks_expr_train.shape,masks_aus_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([1886,  487,  565, 1254, 3751, 1893, 1003, 4601]))\n",
      "[23976  4555  3168  3122 18135  7609  5228 24852] {0: 1.0365365365365367, 1: 5.455982436882547, 2: 7.844696969696971, 3: 7.960281870595772, 4: 1.3703887510339123, 5: 3.266132211854383, 6: 4.7536342769701605, 7: 1.0} 8 [0 1 2 3 4 5 6 7]\n",
      "[1.03653654 5.45598244 7.84469697 7.96028187 1.37038875 3.26613221\n",
      " 4.75363428 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_expr_val[masks_expr_val==1.].astype(int), return_counts=True))\n",
    "\n",
    "(unique, counts) = np.unique(y_expr_train[masks_expr_train==1.].astype(int), return_counts=True)\n",
    "num_classes=len(unique)\n",
    "emo_cw=1/counts\n",
    "#emo_cw*=counts.mean()\n",
    "emo_cw/=emo_cw.min()\n",
    "emo_class_weights = {i:cwi for i,cwi in zip(unique,emo_cw)}\n",
    "print(counts, emo_class_weights, num_classes, unique)\n",
    "print(emo_cw)\n",
    "if False:\n",
    "    emo_cw=np.array([1,5,5,5,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0 84603 18713 [21345  5531]\n",
      "1 94571 8745 [24322  2554]\n",
      "2 82974 20342 [21434  5442]\n",
      "3 72711 30605 [18058  8818]\n",
      "4 61979 41337 [13652 13224]\n",
      "5 65030 38286 [15455 11421]\n",
      "6 76533 26783 [18557  8319]\n",
      "7 100856 2460 [26094   782]\n",
      "8 100336 2980 [26119   757]\n",
      "9 98313 5003 [26068   808]\n",
      "10 32732 70584 [ 6449 20427]\n",
      "11 92560 10756 [23942  2934]\n",
      "[[ 0.610593    2.7605408 ]\n",
      " [ 0.5462351   5.90714694]\n",
      " [ 0.62258057  2.53947498]\n",
      " [ 0.71045646  1.68789413]\n",
      " [ 0.83347585  1.24967946]\n",
      " [ 0.79437183  1.34926605]\n",
      " [ 0.67497681  1.92876078]\n",
      " [ 0.51219561 20.99918699]\n",
      " [ 0.5148501  17.33489933]\n",
      " [ 0.52544424 10.32540476]\n",
      " [ 1.57821093  0.73186558]\n",
      " [ 0.55810285  4.80271476]]\n"
     ]
    }
   ],
   "source": [
    "num_labels=y_aus_train.shape[1]\n",
    "print(num_labels)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "aus_class_weights = np.empty([num_labels, 2])\n",
    "for i in range(num_labels):\n",
    "    neg, pos = np.bincount(y_aus_train[masks_aus_train==1., i])\n",
    "    print(i,neg,pos,np.bincount(y_aus_val[masks_aus_val==1., i]))\n",
    "    total = neg + pos\n",
    "    weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "    weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "    aus_class_weights[i][0]=weight_for_0\n",
    "    aus_class_weights[i][1]=weight_for_1\n",
    "    #aus_class_weights[i] = compute_class_weight('balanced', [0,1], y_train[:, i])\n",
    "print(aus_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_va(y_true, y_pred):\n",
    "    res=1-0.5*(CCC(y_true[:,0], y_pred[:,0])+CCC(y_true[:,1], y_pred[:,1]))\n",
    "    #res=K.mean((y_true[:,0] - y_pred[:,0]) * (y_true[:,0] - y_pred[:,0]))+K.mean((y_true[:,1] - y_pred[:,1]) * (y_true[:,1] - y_pred[:,1]))\n",
    "    #print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedExprSCCE(tf.keras.losses.Loss):\n",
    "    def __init__(self, class_weight, from_logits=False, name='expr_scce'):\n",
    "        if class_weight is None or all(v == 1. for v in class_weight):\n",
    "            self.class_weight = None\n",
    "        else:\n",
    "            self.class_weight = tf.convert_to_tensor(class_weight,\n",
    "                dtype=tf.float32)\n",
    "        self.reduction = tf.keras.losses.Reduction.NONE\n",
    "        self.unreduced_scce = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=from_logits, name=name,\n",
    "            reduction=self.reduction)\n",
    "\n",
    "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
    "        loss = self.unreduced_scce(y_true, y_pred, sample_weight)\n",
    "        if self.class_weight is not None:\n",
    "            weight_mask = tf.gather(self.class_weight, y_true)\n",
    "            loss = tf.math.multiply(loss, weight_mask)\n",
    "        loss=K.mean(loss)\n",
    "        return loss\n",
    "loss_expr=WeightedExprSCCE(emo_cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    def get_weighted_loss_aus(weights):\n",
    "        def weighted_loss(y_true, y_pred):\n",
    "            y_true=tf.cast(y_true, tf.float32)\n",
    "            ce=K.binary_crossentropy(y_true, y_pred)\n",
    "            res=K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*ce)#, axis=-1)\n",
    "            #print(res)\n",
    "            return res\n",
    "        return weighted_loss\n",
    "    loss_aus=get_weighted_loss_aus(aus_class_weights)\n",
    "else:\n",
    "    pos_weights=np.array([1, 2, 1, 1, 1, 1, 1, 6, 6, 5, 1, 5])\n",
    "    def loss_aus(y_true, y_pred):\n",
    "        y_true=tf.cast(y_true, tf.float32)\n",
    "        ce=K.binary_crossentropy(y_true, y_pred)\n",
    "        res=K.mean((pos_weights**(y_true))*ce)#, axis=-1)\n",
    "        #print(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=[tf.keras.metrics.AUC(multi_label=True,name='auc'), tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Recall(),tf.keras.metrics.Precision()] # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTL model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103917.0 90645.0 103316.0\n",
      "26876.0 15440.0 26876.0\n",
      "1.0 1.1464174 1.005817\n"
     ]
    }
   ],
   "source": [
    "num_va_train=masks_va_train.sum()\n",
    "num_expr_train=masks_expr_train.sum()\n",
    "num_aus_train=masks_aus_train.sum()\n",
    "print(num_va_train,num_expr_train,num_aus_train)\n",
    "print(masks_va_val.sum(),masks_expr_val.sum(),masks_aus_val.sum())\n",
    "\n",
    "max_num=max(num_va_train,num_expr_train,num_aus_train)\n",
    "va_weight,expr_weight,aus_weight=max_num/num_va_train,max_num/num_expr_train,max_num/num_aus_train\n",
    "print(va_weight,expr_weight,aus_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256 #128\n",
    "img = tf.keras.Input(shape=X_train.shape[1:])\n",
    "mask1 = tf.keras.Input(shape=(1,))\n",
    "mask2 = tf.keras.Input(shape=(1,))\n",
    "mask3 = tf.keras.Input(shape=(1,))\n",
    "x=img\n",
    "#x=Dense(128, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size))(x)\n",
    "va_out = Dense(2, activation='tanh',kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size))(x)\n",
    "va_out_masked=tf.keras.layers.Multiply(name='va_out')([va_out,mask1])\n",
    "\n",
    "x=tf.keras.layers.Concatenate(axis=1)([x, va_out])\n",
    "#x=va_out\n",
    "\n",
    "aus_out=Dense(12, activation='sigmoid',kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size))(x)\n",
    "aus_out_masked=tf.keras.layers.Multiply(name='aus_out')([aus_out,mask3])\n",
    "\n",
    "#x=tf.keras.layers.Concatenate(axis=1)([x, aus_out])\n",
    "expr_out=Dense(8, activation='softmax',kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size))(x)\n",
    "expr_out_masked=tf.keras.layers.Multiply(name='expr_out')([expr_out,mask2])\n",
    "\n",
    "mtlModel=tf.keras.Model(inputs=[img,mask1,mask2,mask3], outputs=[va_out_masked, expr_out_masked,aus_out_masked])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "if False:\n",
    "    initial_weights=copy.deepcopy(mtlModel.get_weights())\n",
    "else:\n",
    "    mtlModel.set_weights(copy.deepcopy(initial_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 1290)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2)            2582        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 8)            10328       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 12)           15492       input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "va_out (Multiply)               (None, 2)            0           dense_11[0][0]                   \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "expr_out (Multiply)             (None, 8)            0           dense_13[0][0]                   \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "aus_out (Multiply)              (None, 12)           0           dense_12[0][0]                   \n",
      "                                                                 input_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 28,402\n",
      "Trainable params: 28,402\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "556/556 [==============================] - 8s 12ms/step - loss: 4.0585 - va_out_loss: 0.3966 - expr_out_loss: 2.7150 - aus_out_loss: 0.3933 - va_out_mean_absolute_error: 0.1970 - expr_out_accuracy: 0.7297 - aus_out_aus_out_aus_out_auc: 0.8951 - aus_out_aus_out_aus_out_binary_accuracy: 0.8324 - aus_out_aus_out_aus_out_recall_2: 0.7404 - aus_out_aus_out_aus_out_precision_2: 0.4885 - val_loss: 5.8726 - val_va_out_loss: 0.7832 - val_expr_out_loss: 3.7644 - val_aus_out_loss: 0.5721 - val_va_out_mean_absolute_error: 0.2828 - val_expr_out_accuracy: 0.6399 - val_aus_out_aus_out_aus_out_auc: 0.7742 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7428 - val_aus_out_aus_out_aus_out_recall_2: 0.7003 - val_aus_out_aus_out_aus_out_precision_2: 0.4917\n",
      "Epoch 2/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.5186 - va_out_loss: 0.2808 - expr_out_loss: 2.3301 - aus_out_loss: 0.3570 - va_out_mean_absolute_error: 0.1611 - expr_out_accuracy: 0.8144 - aus_out_aus_out_aus_out_auc: 0.8999 - aus_out_aus_out_aus_out_binary_accuracy: 0.8394 - aus_out_aus_out_aus_out_recall_2: 0.7420 - aus_out_aus_out_aus_out_precision_2: 0.5030 - val_loss: 5.8807 - val_va_out_loss: 0.7867 - val_expr_out_loss: 3.7540 - val_aus_out_loss: 0.5669 - val_va_out_mean_absolute_error: 0.2831 - val_expr_out_accuracy: 0.6414 - val_aus_out_aus_out_aus_out_auc: 0.7758 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7359 - val_aus_out_aus_out_aus_out_recall_2: 0.7079 - val_aus_out_aus_out_aus_out_precision_2: 0.4825\n",
      "Epoch 3/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4925 - va_out_loss: 0.2729 - expr_out_loss: 2.3011 - aus_out_loss: 0.3568 - va_out_mean_absolute_error: 0.1582 - expr_out_accuracy: 0.8218 - aus_out_aus_out_aus_out_auc: 0.8992 - aus_out_aus_out_aus_out_binary_accuracy: 0.8383 - aus_out_aus_out_aus_out_recall_2: 0.7429 - aus_out_aus_out_aus_out_precision_2: 0.5014 - val_loss: 5.9960 - val_va_out_loss: 0.7846 - val_expr_out_loss: 3.8493 - val_aus_out_loss: 0.5697 - val_va_out_mean_absolute_error: 0.2857 - val_expr_out_accuracy: 0.6362 - val_aus_out_aus_out_aus_out_auc: 0.7748 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7245 - val_aus_out_aus_out_aus_out_recall_2: 0.7123 - val_aus_out_aus_out_aus_out_precision_2: 0.4682\n",
      "Epoch 4/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4919 - va_out_loss: 0.2709 - expr_out_loss: 2.3002 - aus_out_loss: 0.3562 - va_out_mean_absolute_error: 0.1565 - expr_out_accuracy: 0.8209 - aus_out_aus_out_aus_out_auc: 0.8996 - aus_out_aus_out_aus_out_binary_accuracy: 0.8373 - aus_out_aus_out_aus_out_recall_2: 0.7447 - aus_out_aus_out_aus_out_precision_2: 0.4982 - val_loss: 5.9121 - val_va_out_loss: 0.7877 - val_expr_out_loss: 3.7707 - val_aus_out_loss: 0.5703 - val_va_out_mean_absolute_error: 0.2856 - val_expr_out_accuracy: 0.6394 - val_aus_out_aus_out_aus_out_auc: 0.7762 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7416 - val_aus_out_aus_out_aus_out_recall_2: 0.7081 - val_aus_out_aus_out_aus_out_precision_2: 0.4902\n",
      "Epoch 5/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4861 - va_out_loss: 0.2699 - expr_out_loss: 2.2945 - aus_out_loss: 0.3555 - va_out_mean_absolute_error: 0.1556 - expr_out_accuracy: 0.8204 - aus_out_aus_out_aus_out_auc: 0.8993 - aus_out_aus_out_aus_out_binary_accuracy: 0.8397 - aus_out_aus_out_aus_out_recall_2: 0.7425 - aus_out_aus_out_aus_out_precision_2: 0.5019 - val_loss: 5.8343 - val_va_out_loss: 0.7881 - val_expr_out_loss: 3.7052 - val_aus_out_loss: 0.5679 - val_va_out_mean_absolute_error: 0.2830 - val_expr_out_accuracy: 0.6406 - val_aus_out_aus_out_aus_out_auc: 0.7742 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7341 - val_aus_out_aus_out_aus_out_recall_2: 0.7202 - val_aus_out_aus_out_aus_out_precision_2: 0.4804\n",
      "Epoch 6/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4942 - va_out_loss: 0.2712 - expr_out_loss: 2.3001 - aus_out_loss: 0.3560 - va_out_mean_absolute_error: 0.1565 - expr_out_accuracy: 0.8202 - aus_out_aus_out_aus_out_auc: 0.8988 - aus_out_aus_out_aus_out_binary_accuracy: 0.8388 - aus_out_aus_out_aus_out_recall_2: 0.7437 - aus_out_aus_out_aus_out_precision_2: 0.4993 - val_loss: 5.8965 - val_va_out_loss: 0.7937 - val_expr_out_loss: 3.7524 - val_aus_out_loss: 0.5697 - val_va_out_mean_absolute_error: 0.2815 - val_expr_out_accuracy: 0.6400 - val_aus_out_aus_out_aus_out_auc: 0.7745 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7355 - val_aus_out_aus_out_aus_out_recall_2: 0.7183 - val_aus_out_aus_out_aus_out_precision_2: 0.4823\n",
      "Epoch 7/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4830 - va_out_loss: 0.2679 - expr_out_loss: 2.2934 - aus_out_loss: 0.3560 - va_out_mean_absolute_error: 0.1551 - expr_out_accuracy: 0.8252 - aus_out_aus_out_aus_out_auc: 0.8989 - aus_out_aus_out_aus_out_binary_accuracy: 0.8395 - aus_out_aus_out_aus_out_recall_2: 0.7412 - aus_out_aus_out_aus_out_precision_2: 0.5011 - val_loss: 5.8692 - val_va_out_loss: 0.7893 - val_expr_out_loss: 3.7366 - val_aus_out_loss: 0.5659 - val_va_out_mean_absolute_error: 0.2851 - val_expr_out_accuracy: 0.6387 - val_aus_out_aus_out_aus_out_auc: 0.7772 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7276 - val_aus_out_aus_out_aus_out_recall_2: 0.7154 - val_aus_out_aus_out_aus_out_precision_2: 0.4721\n",
      "Epoch 8/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4824 - va_out_loss: 0.2669 - expr_out_loss: 2.2955 - aus_out_loss: 0.3545 - va_out_mean_absolute_error: 0.1553 - expr_out_accuracy: 0.8207 - aus_out_aus_out_aus_out_auc: 0.8998 - aus_out_aus_out_aus_out_binary_accuracy: 0.8405 - aus_out_aus_out_aus_out_recall_2: 0.7442 - aus_out_aus_out_aus_out_precision_2: 0.5045 - val_loss: 5.9280 - val_va_out_loss: 0.7873 - val_expr_out_loss: 3.7862 - val_aus_out_loss: 0.5690 - val_va_out_mean_absolute_error: 0.2814 - val_expr_out_accuracy: 0.6376 - val_aus_out_aus_out_aus_out_auc: 0.7750 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7343 - val_aus_out_aus_out_aus_out_recall_2: 0.7082 - val_aus_out_aus_out_aus_out_precision_2: 0.4805\n",
      "Epoch 9/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4843 - va_out_loss: 0.2691 - expr_out_loss: 2.2950 - aus_out_loss: 0.3548 - va_out_mean_absolute_error: 0.1560 - expr_out_accuracy: 0.8226 - aus_out_aus_out_aus_out_auc: 0.8992 - aus_out_aus_out_aus_out_binary_accuracy: 0.8415 - aus_out_aus_out_aus_out_recall_2: 0.7421 - aus_out_aus_out_aus_out_precision_2: 0.5054 - val_loss: 5.9216 - val_va_out_loss: 0.7913 - val_expr_out_loss: 3.7786 - val_aus_out_loss: 0.5673 - val_va_out_mean_absolute_error: 0.2814 - val_expr_out_accuracy: 0.6401 - val_aus_out_aus_out_aus_out_auc: 0.7758 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7298 - val_aus_out_aus_out_aus_out_recall_2: 0.7226 - val_aus_out_aus_out_aus_out_precision_2: 0.4751\n",
      "Epoch 10/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4851 - va_out_loss: 0.2702 - expr_out_loss: 2.2931 - aus_out_loss: 0.3568 - va_out_mean_absolute_error: 0.1565 - expr_out_accuracy: 0.8234 - aus_out_aus_out_aus_out_auc: 0.8987 - aus_out_aus_out_aus_out_binary_accuracy: 0.8385 - aus_out_aus_out_aus_out_recall_2: 0.7443 - aus_out_aus_out_aus_out_precision_2: 0.5015 - val_loss: 5.9231 - val_va_out_loss: 0.7877 - val_expr_out_loss: 3.7825 - val_aus_out_loss: 0.5679 - val_va_out_mean_absolute_error: 0.2840 - val_expr_out_accuracy: 0.6382 - val_aus_out_aus_out_aus_out_auc: 0.7750 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7333 - val_aus_out_aus_out_aus_out_recall_2: 0.7175 - val_aus_out_aus_out_aus_out_precision_2: 0.4794\n",
      "Epoch 11/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4885 - va_out_loss: 0.2679 - expr_out_loss: 2.2975 - aus_out_loss: 0.3558 - va_out_mean_absolute_error: 0.1561 - expr_out_accuracy: 0.8226 - aus_out_aus_out_aus_out_auc: 0.8995 - aus_out_aus_out_aus_out_binary_accuracy: 0.8402 - aus_out_aus_out_aus_out_recall_2: 0.7453 - aus_out_aus_out_aus_out_precision_2: 0.5053 - val_loss: 5.8560 - val_va_out_loss: 0.7922 - val_expr_out_loss: 3.7218 - val_aus_out_loss: 0.5671 - val_va_out_mean_absolute_error: 0.2801 - val_expr_out_accuracy: 0.6398 - val_aus_out_aus_out_aus_out_auc: 0.7783 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7376 - val_aus_out_aus_out_aus_out_recall_2: 0.7092 - val_aus_out_aus_out_aus_out_precision_2: 0.4848\n",
      "Epoch 12/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4871 - va_out_loss: 0.2709 - expr_out_loss: 2.2944 - aus_out_loss: 0.3577 - va_out_mean_absolute_error: 0.1567 - expr_out_accuracy: 0.8232 - aus_out_aus_out_aus_out_auc: 0.8990 - aus_out_aus_out_aus_out_binary_accuracy: 0.8387 - aus_out_aus_out_aus_out_recall_2: 0.7424 - aus_out_aus_out_aus_out_precision_2: 0.5012 - val_loss: 5.8898 - val_va_out_loss: 0.7952 - val_expr_out_loss: 3.7441 - val_aus_out_loss: 0.5694 - val_va_out_mean_absolute_error: 0.2818 - val_expr_out_accuracy: 0.6387 - val_aus_out_aus_out_aus_out_auc: 0.7759 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7459 - val_aus_out_aus_out_aus_out_recall_2: 0.7184 - val_aus_out_aus_out_aus_out_precision_2: 0.4960\n",
      "Epoch 13/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4842 - va_out_loss: 0.2675 - expr_out_loss: 2.2970 - aus_out_loss: 0.3540 - va_out_mean_absolute_error: 0.1555 - expr_out_accuracy: 0.8233 - aus_out_aus_out_aus_out_auc: 0.8993 - aus_out_aus_out_aus_out_binary_accuracy: 0.8423 - aus_out_aus_out_aus_out_recall_2: 0.7445 - aus_out_aus_out_aus_out_precision_2: 0.5085 - val_loss: 5.8905 - val_va_out_loss: 0.7887 - val_expr_out_loss: 3.7542 - val_aus_out_loss: 0.5675 - val_va_out_mean_absolute_error: 0.2837 - val_expr_out_accuracy: 0.6416 - val_aus_out_aus_out_aus_out_auc: 0.7766 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7355 - val_aus_out_aus_out_aus_out_recall_2: 0.7160 - val_aus_out_aus_out_aus_out_precision_2: 0.4822\n",
      "Epoch 14/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4884 - va_out_loss: 0.2697 - expr_out_loss: 2.2977 - aus_out_loss: 0.3550 - va_out_mean_absolute_error: 0.1558 - expr_out_accuracy: 0.8222 - aus_out_aus_out_aus_out_auc: 0.8995 - aus_out_aus_out_aus_out_binary_accuracy: 0.8400 - aus_out_aus_out_aus_out_recall_2: 0.7439 - aus_out_aus_out_aus_out_precision_2: 0.5031 - val_loss: 5.9004 - val_va_out_loss: 0.7863 - val_expr_out_loss: 3.7628 - val_aus_out_loss: 0.5689 - val_va_out_mean_absolute_error: 0.2843 - val_expr_out_accuracy: 0.6332 - val_aus_out_aus_out_aus_out_auc: 0.7746 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7311 - val_aus_out_aus_out_aus_out_recall_2: 0.7206 - val_aus_out_aus_out_aus_out_precision_2: 0.4767\n",
      "Epoch 15/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4769 - va_out_loss: 0.2686 - expr_out_loss: 2.2879 - aus_out_loss: 0.3553 - va_out_mean_absolute_error: 0.1560 - expr_out_accuracy: 0.8229 - aus_out_aus_out_aus_out_auc: 0.8991 - aus_out_aus_out_aus_out_binary_accuracy: 0.8403 - aus_out_aus_out_aus_out_recall_2: 0.7442 - aus_out_aus_out_aus_out_precision_2: 0.5033 - val_loss: 5.9247 - val_va_out_loss: 0.7901 - val_expr_out_loss: 3.7837 - val_aus_out_loss: 0.5682 - val_va_out_mean_absolute_error: 0.2853 - val_expr_out_accuracy: 0.6373 - val_aus_out_aus_out_aus_out_auc: 0.7750 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7372 - val_aus_out_aus_out_aus_out_recall_2: 0.7152 - val_aus_out_aus_out_aus_out_precision_2: 0.4844\n",
      "Epoch 16/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4990 - va_out_loss: 0.2688 - expr_out_loss: 2.3072 - aus_out_loss: 0.3564 - va_out_mean_absolute_error: 0.1565 - expr_out_accuracy: 0.8228 - aus_out_aus_out_aus_out_auc: 0.8996 - aus_out_aus_out_aus_out_binary_accuracy: 0.8387 - aus_out_aus_out_aus_out_recall_2: 0.7434 - aus_out_aus_out_aus_out_precision_2: 0.5012 - val_loss: 5.8063 - val_va_out_loss: 0.7943 - val_expr_out_loss: 3.6745 - val_aus_out_loss: 0.5700 - val_va_out_mean_absolute_error: 0.2841 - val_expr_out_accuracy: 0.6457 - val_aus_out_aus_out_aus_out_auc: 0.7750 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7439 - val_aus_out_aus_out_aus_out_recall_2: 0.7094 - val_aus_out_aus_out_aus_out_precision_2: 0.4932\n",
      "Epoch 17/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.5013 - va_out_loss: 0.2681 - expr_out_loss: 2.3110 - aus_out_loss: 0.3552 - va_out_mean_absolute_error: 0.1563 - expr_out_accuracy: 0.8214 - aus_out_aus_out_aus_out_auc: 0.8999 - aus_out_aus_out_aus_out_binary_accuracy: 0.8405 - aus_out_aus_out_aus_out_recall_2: 0.7447 - aus_out_aus_out_aus_out_precision_2: 0.5059 - val_loss: 5.8887 - val_va_out_loss: 0.7887 - val_expr_out_loss: 3.7524 - val_aus_out_loss: 0.5684 - val_va_out_mean_absolute_error: 0.2851 - val_expr_out_accuracy: 0.6360 - val_aus_out_aus_out_aus_out_auc: 0.7759 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7333 - val_aus_out_aus_out_aus_out_recall_2: 0.7223 - val_aus_out_aus_out_aus_out_precision_2: 0.4795\n",
      "Epoch 18/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4941 - va_out_loss: 0.2688 - expr_out_loss: 2.3016 - aus_out_loss: 0.3573 - va_out_mean_absolute_error: 0.1560 - expr_out_accuracy: 0.8219 - aus_out_aus_out_aus_out_auc: 0.8982 - aus_out_aus_out_aus_out_binary_accuracy: 0.8381 - aus_out_aus_out_aus_out_recall_2: 0.7455 - aus_out_aus_out_aus_out_precision_2: 0.5001 - val_loss: 5.8476 - val_va_out_loss: 0.7942 - val_expr_out_loss: 3.7122 - val_aus_out_loss: 0.5693 - val_va_out_mean_absolute_error: 0.2817 - val_expr_out_accuracy: 0.6373 - val_aus_out_aus_out_aus_out_auc: 0.7751 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7432 - val_aus_out_aus_out_aus_out_recall_2: 0.7157 - val_aus_out_aus_out_aus_out_precision_2: 0.4923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4946 - va_out_loss: 0.2684 - expr_out_loss: 2.3042 - aus_out_loss: 0.3561 - va_out_mean_absolute_error: 0.1562 - expr_out_accuracy: 0.8233 - aus_out_aus_out_aus_out_auc: 0.8988 - aus_out_aus_out_aus_out_binary_accuracy: 0.8408 - aus_out_aus_out_aus_out_recall_2: 0.7448 - aus_out_aus_out_aus_out_precision_2: 0.5067 - val_loss: 5.8605 - val_va_out_loss: 0.7890 - val_expr_out_loss: 3.7284 - val_aus_out_loss: 0.5693 - val_va_out_mean_absolute_error: 0.2842 - val_expr_out_accuracy: 0.6358 - val_aus_out_aus_out_aus_out_auc: 0.7754 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7394 - val_aus_out_aus_out_aus_out_recall_2: 0.7141 - val_aus_out_aus_out_aus_out_precision_2: 0.4872\n",
      "Epoch 20/20\n",
      "556/556 [==============================] - 6s 11ms/step - loss: 3.4814 - va_out_loss: 0.2670 - expr_out_loss: 2.2931 - aus_out_loss: 0.3570 - va_out_mean_absolute_error: 0.1556 - expr_out_accuracy: 0.8240 - aus_out_aus_out_aus_out_auc: 0.8989 - aus_out_aus_out_aus_out_binary_accuracy: 0.8390 - aus_out_aus_out_aus_out_recall_2: 0.7465 - aus_out_aus_out_aus_out_precision_2: 0.5030 - val_loss: 5.8901 - val_va_out_loss: 0.7948 - val_expr_out_loss: 3.7487 - val_aus_out_loss: 0.5688 - val_va_out_mean_absolute_error: 0.2815 - val_expr_out_accuracy: 0.6373 - val_aus_out_aus_out_aus_out_auc: 0.7758 - val_aus_out_aus_out_aus_out_binary_accuracy: 0.7420 - val_aus_out_aus_out_aus_out_recall_2: 0.7124 - val_aus_out_aus_out_aus_out_precision_2: 0.4907\n",
      "5.806302070617676\n"
     ]
    }
   ],
   "source": [
    "mtlModel.compile(optimizer=Adam(lr=1e-3), loss=[loss_va,loss_expr,loss_aus], loss_weights=[va_weight,expr_weight,aus_weight],\n",
    "                 metrics=[[\"mean_absolute_error\"], [\"accuracy\"],metrics])\n",
    "mtlModel.summary()\n",
    "\n",
    "save_best_model = SaveBestModel('val_loss',False)\n",
    "mtlModel.fit([X_train,masks_va_train,masks_expr_train,masks_aus_train],\n",
    "             [y_va_train,y_expr_train,y_aus_train], batch_size=batch_size, epochs=(1 if TRAIN_VAL else 20), \n",
    "             verbose=1, callbacks=[save_best_model], \n",
    "             validation_data=([X_val,masks_va_val,masks_expr_val,masks_aus_val],[y_va_val,y_expr_val,y_aus_val]))\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all():\n",
    "    y_pred_va,y_pred_expr,y_pred_aus=mtlModel.predict([X_val,masks_va_val,masks_expr_val,masks_aus_val])\n",
    "    print('\\nAV')\n",
    "    gt_V=y_va_val[masks_va_val==1,0]\n",
    "    gt_A=y_va_val[masks_va_val==1,1]\n",
    "    pred_V=y_pred_va[masks_va_val==1,0]\n",
    "    pred_A=y_pred_va[masks_va_val==1,1]\n",
    "    ccc_V,ccc_A,ccc_VA=metric_for_VA(gt_V,gt_A,pred_V,pred_A)\n",
    "    print(gt_V.shape,ccc_V,ccc_A,ccc_VA)\n",
    "    \n",
    "    print('\\nExpression')\n",
    "    print(y_expr_val[masks_expr_val==1].shape)\n",
    "    y_pred=np.argmax(y_pred_expr,axis=1)\n",
    "    print((y_pred==y_expr_val)[masks_expr_val==1].mean())\n",
    "    f1_expr=f1_score(y_true=y_expr_val[masks_expr_val==1],y_pred=y_pred[masks_expr_val==1], average=\"macro\")\n",
    "    print(f1_expr)\n",
    "    print(metric_for_Exp(y_expr_val[masks_expr_val==1],y_pred[masks_expr_val==1]))\n",
    "    \n",
    "    print('\\nAUs')\n",
    "    new_pred = ((y_pred_aus >= 0.5) * 1)\n",
    "    print(new_pred[masks_aus_val==1,:].shape)\n",
    "    f1_au=np.mean([f1_score(y_true=y_aus_val[masks_aus_val==1,i],y_pred=new_pred[masks_aus_val==1,i]) for i in range(y_pred_aus.shape[1])])\n",
    "    print(f1_au)\n",
    "    print(f1_score_max(y_aus_val[masks_aus_val==1,:],y_pred_aus[masks_aus_val==1,:],thresh=np.arange(0.1,1,0.1)))\n",
    "    \n",
    "    total=ccc_VA+f1_expr+f1_au\n",
    "    print('\\nTotal',ccc_VA,f1_expr,f1_au,total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AV\n",
      "(26876,) 0.43934089966270284 0.3850961736511451 0.412218536656924\n",
      "\n",
      "Expression\n",
      "(15440,)\n",
      "0.3687176165803109\n",
      "0.31968436000718103\n",
      "(0.31968436000718103, 0.3687176165803109, [0.3875251509054326, 0.3013923013923014, 0.5357483317445185, 0.03164556962025317, 0.46005938074367314, 0.33871602993304456, 0.11230856494611458, 0.39007955077211043])\n",
      "\n",
      "AUs\n",
      "(26876, 12)\n",
      "0.46590581560224126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.49368479684460276, 0.5750000000000001, array([0.56099218, 0.44302449, 0.56837571, 0.56656315, 0.72636587,\n",
      "       0.70537923, 0.66032561, 0.13768524, 0.1047619 , 0.21239954,\n",
      "       0.87793932, 0.3604053 ]), array([0.6, 0.7, 0.6, 0.5, 0.4, 0.5, 0.5, 0.6, 0.7, 0.8, 0.3, 0.7]), array([0.80770948, 0.88324155, 0.80610954, 0.6884209 , 0.68972317,\n",
      "       0.73853996, 0.78341271, 0.8289552 , 0.96502456, 0.94895074,\n",
      "       0.80164459, 0.84733591]))\n",
      "\n",
      "Total 0.412218536656924 0.31968436000718103 0.46590581560224126 1.1978087122663463\n"
     ]
    }
   ],
   "source": [
    "print_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best weights:\n",
      "\n",
      "AV\n",
      "(26876,) 0.446480673138777 0.3701610243422664 0.40832084874052166\n",
      "\n",
      "Expression\n",
      "(15440,)\n",
      "0.38335492227979273\n",
      "0.32960438325217256\n",
      "(0.32960438325217256, 0.38335492227979273, [0.3923031612016493, 0.3071230342275671, 0.5136921624173748, 0.053571428571428575, 0.4546750285062714, 0.4235209235209235, 0.08527648234510327, 0.4066728452270621])\n",
      "\n",
      "AUs\n",
      "(26876, 12)\n",
      "0.4648836547544832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.49390624765786967, 0.5666666666666668, array([0.55765854, 0.43717001, 0.56655927, 0.56776138, 0.72728473,\n",
      "       0.70859504, 0.66182415, 0.13815926, 0.10613944, 0.21597957,\n",
      "       0.87757485, 0.36216875]), array([0.7, 0.7, 0.6, 0.5, 0.4, 0.5, 0.5, 0.6, 0.7, 0.7, 0.2, 0.7]), array([0.8312993 , 0.88100908, 0.80979312, 0.69050454, 0.69255097,\n",
      "       0.73760976, 0.78519869, 0.84495461, 0.9680384 , 0.92004018,\n",
      "       0.7932356 , 0.84417324]))\n",
      "\n",
      "Total 0.40832084874052166 0.32960438325217256 0.4648836547544832 1.2028088867471773\n"
     ]
    }
   ],
   "source": [
    "print('Best weights:')\n",
    "mtlModel.set_weights(best_model_weights)\n",
    "print_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AV\n",
      "(26876,) 0.441977966779619 0.3783160424524422 0.4101470046160306\n",
      "\n",
      "Expression\n",
      "(15440,)\n",
      "0.3645077720207254\n",
      "0.30374060068461467\n",
      "(0.30374060068461467, 0.3645077720207254, [0.3225108225108225, 0.306320907617504, 0.36872812135355904, 0.0, 0.48519040902679833, 0.3380281690140845, 0.2184441009788769, 0.39070227497527205])\n",
      "\n",
      "AUs\n",
      "(26876, 12)\n",
      "0.4453343451586555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4762028954542939, 0.5333333333333333, array([0.53098316, 0.42112483, 0.54961963, 0.55606101, 0.71629462,\n",
      "       0.69021277, 0.65632557, 0.11511433, 0.07011592, 0.17885679,\n",
      "       0.87514832, 0.35457781]), array([0.6, 0.7, 0.6, 0.4, 0.4, 0.5, 0.5, 0.5, 0.6, 0.7, 0.2, 0.7]), array([0.7772362 , 0.87438607, 0.80395148, 0.62963239, 0.67796547,\n",
      "       0.72912636, 0.78318946, 0.70482959, 0.87762316, 0.90058044,\n",
      "       0.78858461, 0.85154041]))\n",
      "\n",
      "Total 0.4101470046160306 0.30374060068461467 0.4453343451586555 1.1592219504593009\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    #mtlModel.save_weights('mtl_enet2_8.h5') #0.3837151018856935 0.3022424974391059 0.46080879636948063 1.1467663956942802\n",
    "    #mtlModel.save_weights('mtl_enet2_8.h5') #0.38941268091453485 0.2966496393771772 0.46193077632133167 1.1479930966130436\n",
    "    #mtlModel.save_weights('mtl_enet0_vgaf.h5') #0.4101470046160306 0.30374060068461467 0.4453343451586555 1.1592219504593009\n",
    "    #mtlModel.save_weights('mtl_enet0_mtl_scores.h5') #0.41964194296471674 0.3108849599582243 0.4495678236137662 1.1800947265367072\n",
    "    #mtlModel.save_weights('mtl_enet0_mtl_features.h5') #0.4077160039302934 0.3304590574311655 0.46342233378866404 1.2015973951501229\n",
    "    mtlModel.save_weights('mtl_enet0_mtl_features_new.h5') #0.4205420369528933 0.32631765971330484 0.4666244179960605 1.2134841146622586\n",
    "    #0.41443352670757555 0.33392390239905834 0.4631641154858293 1.2115215445924632\n",
    "else:\n",
    "    #mtlModel.load_weights('mtl_enet2_8_orig.h5')\n",
    "    mtlModel.load_weights('mtl_enet0_vgaf.h5')\n",
    "    #mtlModel.load_weights('mtl_enet0_mtl_features_new.h5')\n",
    "    print_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mobilenet\n",
    "output layers only: 0.3575652288180158 0.274931498498287 0.4667221169978419 1.0992188443141446\n",
    "0.35813183800284104 0.2823732083688107 0.47113929424277273 1.1116443406144245\n",
    "dense layer: 0.3212823862697798 0.25187087483194115 0.46361689956738755 1.0367701606691084\n",
    "\n",
    "enet0_7\n",
    "output layers only:0.37147839426933726 0.2862848390733215 0.4561286864943848 1.1138919198370436\n",
    "dense layer: 0.37387452943730165 0.2522474413566924 0.4641164043127432 1.0902383751067373\n",
    "not best 0.3944477107433102 0.23835206524054334 0.4603934421520726 1.093193218135926\n",
    "\n",
    "enet_b0_8_best_afew\n",
    "features+emotions\n",
    "output layers only:0.4026537613423008 0.248547670046962 0.45890535417538064 1.1101067855646434\n",
    "\n",
    "\n",
    "enet_b0_8_best_vgaf\n",
    "features+emotions\n",
    "output layers only:0.38615587195723955 0.282608775233668 0.4545389225496568 1.1233035697405644\n",
    "dense: 0.3808455198959431 0.27195008480301336 0.46871028488210437 1.1215058895810608\n",
    "\n",
    "SR:\n",
    "0.37119770014719833 0.2455657651558003 0.45512883392676473 1.0718922992297633\n",
    "aligned:\n",
    "0.39612867971292187 0.29007220939613076 0.4618770485417234 1.148077937650776\n",
    "\n",
    "scores, new model (concat VA): 0.4101470046160306 0.30374060068461467 0.4453343451586555 1.1592219504593009\n",
    "\n",
    "mtl_enet0_mtl: \n",
    "scores only: 0.41964194296471674 0.3108849599582243 0.4495678236137662 1.1800947265367072\n",
    "features only: 0.4148349771535716 0.30801118050190446 0.4667824146670865 1.1896285723225626\n",
    "scores+features: \n",
    "new network: 0.41443352670757555 0.33392390239905834 0.4631641154858293 1.2115215445924632\n",
    "previous: 0.4206581824810957 0.32312430364131917 0.4612318367279269 1.2050143228503418\n",
    "\n",
    "SR:scores 0.397964255040454 0.2888308244878144 0.4556445368596133 1.1424396163878818\n",
    "\n",
    "\n",
    "enet2_8\n",
    "output layers only: 0.38307364079552575 0.28723802667892157 0.4593295818373552 1.1296412493118027\n",
    "dense layer: 0.3966562712594687 0.281604125663917 0.45615746671167773 1.1344178636350635\n",
    "\n",
    "features+emotions\n",
    "0.3837151018856935 0.3022424974391059 0.46080879636948063 1.1467663956942802\n",
    "+dense: 0.3779975030622512 0.2987745729052591 0.45822890901489305 1.1350009849824034\n",
    "\n",
    "\n",
    "enet2_7\n",
    "features\n",
    "output layers only: 0.39352969999919685 0.2741800561672634 0.4611839520090892 1.1288937081755495\n",
    "dense layer: 0.3678038228570031 0.2800059725435074 0.4564833238081867 1.104293119208697\n",
    "\n",
    "features+emotions\n",
    "output layers only: 0.38307364079552575 0.28723802667892157 0.4593295818373552 1.1296412493118027\n",
    "dense layer:  0.3919721221529454 0.2821609899822945 0.460412089791669 1.1345452019269089"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTL model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90645, 1290) (90645,) (15440, 1290) (15440,)\n",
      "(103917, 1290) (103917, 2) (26876, 1290) (26876, 2)\n",
      "(103316, 1290) (103316, 12) (26876, 1290) (26876, 12)\n"
     ]
    }
   ],
   "source": [
    "X_expr_only_train,y_expr_only_train=X_train[masks_expr_train==1],y_expr_train[masks_expr_train==1]\n",
    "X_expr_only_val,y_expr_only_val=X_val[masks_expr_val==1],y_expr_val[masks_expr_val==1]\n",
    "print(X_expr_only_train.shape,y_expr_only_train.shape,X_expr_only_val.shape,y_expr_only_val.shape)\n",
    "\n",
    "X_va_only_train,y_va_only_train=X_train[masks_va_train==1],y_va_train[masks_va_train==1]\n",
    "X_va_only_val,y_va_only_val=X_val[masks_va_val==1],y_va_val[masks_va_val==1]\n",
    "print(X_va_only_train.shape,y_va_only_train.shape,X_va_only_val.shape,y_va_only_val.shape)\n",
    "\n",
    "X_au_only_train,y_au_only_train=X_train[masks_aus_train==1],y_aus_train[masks_aus_train==1]\n",
    "X_au_only_val,y_au_only_val=X_val[masks_aus_val==1],y_aus_val[masks_aus_val==1]\n",
    "print(X_au_only_train.shape,y_au_only_train.shape,X_au_only_val.shape,y_au_only_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Slice(tf.keras.layers.Layer):\n",
    "    def __init__(self, begin, size,**kwargs):\n",
    "        super(Slice, self).__init__(**kwargs)\n",
    "        self.begin = begin\n",
    "        self.size = size\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'begin': self.begin,\n",
    "            'size': self.size,\n",
    "        })\n",
    "        return config\n",
    "    def call(self, inputs):\n",
    "        #return tf.slice(inputs, self.begin, self.size)\n",
    "        return inputs[:,self.begin:self.begin+self.size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "img = tf.keras.Input(shape=X_train.shape[1:])\n",
    "x=img\n",
    "#x=Dense(128, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size))(x)\n",
    "if True:\n",
    "    expr_out=Dense(8, activation='softmax',kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size))(x)\n",
    "else:\n",
    "    s_l=Slice(0,1280)(x)\n",
    "    expr_out=Dense(8, activation='softmax',kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size))(s_l)\n",
    "if False:\n",
    "    va_out = Dense(2, activation='tanh',kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size))(x)\n",
    "else:\n",
    "    s_l=Slice(1280,10)(x)\n",
    "    va_out = Dense(2, activation='tanh',kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size))(s_l)\n",
    "    \n",
    "if False:\n",
    "    aus_out=Dense(12, activation='sigmoid',kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size))(x)\n",
    "else:\n",
    "    au_fc=Dense(128,activation='relu')(x)\n",
    "    aus_out=Dense(12, activation='sigmoid')(au_fc)\n",
    "\n",
    "mtl_model_new=tf.keras.Model(inputs=img, outputs=[expr_out, va_out, aus_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "if True:\n",
    "    initial_weights=copy.deepcopy(mtl_model_new.get_weights())\n",
    "else:\n",
    "    mtl_model_new.set_weights(copy.deepcopy(initial_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1290)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 10328     \n",
      "=================================================================\n",
      "Total params: 10,328\n",
      "Trainable params: 10,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 3.3695 - accuracy: 0.4528 - val_loss: 1.8048 - val_accuracy: 0.3453\n",
      "Epoch 2/10\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 2.1699 - accuracy: 0.6471 - val_loss: 1.8506 - val_accuracy: 0.3508\n",
      "Epoch 3/10\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 1.9914 - accuracy: 0.6855 - val_loss: 1.9130 - val_accuracy: 0.3360\n",
      "Epoch 4/10\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 1.9104 - accuracy: 0.7018 - val_loss: 1.9433 - val_accuracy: 0.3372\n",
      "Epoch 5/10\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 1.8856 - accuracy: 0.7152 - val_loss: 1.9833 - val_accuracy: 0.3348\n",
      "Epoch 6/10\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 1.8474 - accuracy: 0.7192 - val_loss: 1.9779 - val_accuracy: 0.3381\n",
      "Epoch 7/10\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 1.8566 - accuracy: 0.7255 - val_loss: 1.9906 - val_accuracy: 0.3366\n",
      "Epoch 8/10\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 1.8335 - accuracy: 0.7305 - val_loss: 2.0109 - val_accuracy: 0.3366\n",
      "Epoch 9/10\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 1.8455 - accuracy: 0.7289 - val_loss: 2.0271 - val_accuracy: 0.3328\n",
      "Epoch 10/10\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 1.8232 - accuracy: 0.7312 - val_loss: 2.0414 - val_accuracy: 0.3318\n",
      "0.3508419692516327\n"
     ]
    }
   ],
   "source": [
    "model_expr=tf.keras.Model(inputs=img, outputs=expr_out)\n",
    "model_expr.compile(optimizer=Adam(lr=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_expr.summary()\n",
    "\n",
    "save_best_model = SaveBestModel('val_accuracy',True)\n",
    "model_expr.fit(X_expr_only_train,y_expr_only_train, batch_size=batch_size, epochs=(1 if TRAIN_VAL else 10), verbose=1, \n",
    "             callbacks=[save_best_model], validation_data=(X_expr_only_val,y_expr_only_val),class_weight=emo_class_weights)\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_expr():\n",
    "    y_val_preds,_,_=mtl_model_new.predict(X_val)\n",
    "    y_pred=np.argmax(y_val_preds,axis=1)[masks_expr_val==1]\n",
    "    print('Acc:',(y_pred==y_expr_only_val).mean(), 'F1:',f1_score(y_true=y_expr_only_val,y_pred=y_pred, average=\"macro\"))\n",
    "    print(metric_for_Exp(y_expr_only_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.331800518134715 F1: 0.31392339895916155\n",
      "(0.31392339895916155, 0.331800518134715, [0.34149926506614403, 0.21656686626746505, 0.3997728563316298, 0.22598870056497175, 0.47736865085140445, 0.39370654957921697, 0.16640986132511557, 0.2900744416873449])\n",
      "Best weights:\n",
      "Acc: 0.3508419689119171 F1: 0.3362736789002177\n",
      "(0.3362736789002177, 0.3508419689119171, [0.34167468719923, 0.2123015873015873, 0.41098901098901097, 0.27903469079939663, 0.4929203539823009, 0.46383701188455, 0.1916354556803995, 0.2977966333652662])\n"
     ]
    }
   ],
   "source": [
    "if not TRAIN_VAL:\n",
    "    print_expr()\n",
    "    print('Best weights:')\n",
    "    model_expr.set_weights(best_model_weights)\n",
    "print_expr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features only\n",
    "Acc: 0.35582901554404145 F1: 0.33853939646012643\n",
    "(0.33853939646012643, 0.35582901554404145, [0.3362332471196803, 0.20376629647513278, 0.4379915305505142, 0.2291891891891892, 0.5075120192307693, 0.4421906693711967, 0.22203048605119355, 0.32940173369333525])\n",
    "\n",
    "scores only\n",
    "Best weights:\n",
    "Acc: 0.280699481865285 F1: 0.2605997985451292\n",
    "(0.2605997985451292, 0.280699481865285, [0.29420360448124694, 0.18459495351925634, 0.24043715846994537, 0.1410153102336825, 0.46742292030250154, 0.37460913070669166, 0.2737528202557032, 0.10876249039200615])\n",
    "\n",
    "scores+features\n",
    "Acc: 0.3480569948186529 F1: 0.3334845842529065\n",
    "(0.3334845842529065, 0.3480569948186529, [0.3404950957496497, 0.21566632756866735, 0.41048522030117124, 0.28926553672316385, 0.47647409172126265, 0.4472135687088958, 0.18200134318334452, 0.3062754900670965])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valence-arousal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1290)]            0         \n",
      "_________________________________________________________________\n",
      "slice (Slice)                (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 22\n",
      "Trainable params: 22\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "203/203 [==============================] - 2s 6ms/step - loss: 1.1153 - mae: 0.7420 - mse: 0.7599 - val_loss: 0.9710 - val_mae: 0.6732 - val_mse: 0.6497\n",
      "Epoch 2/20\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.9301 - mae: 0.6797 - mse: 0.6436 - val_loss: 0.9086 - val_mae: 0.6148 - val_mse: 0.5445\n",
      "Epoch 3/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.7997 - mae: 0.6087 - mse: 0.5191 - val_loss: 0.8403 - val_mae: 0.5578 - val_mse: 0.4540\n",
      "Epoch 4/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.7111 - mae: 0.5591 - mse: 0.4458 - val_loss: 0.8223 - val_mae: 0.5261 - val_mse: 0.4121\n",
      "Epoch 5/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.6857 - mae: 0.5251 - mse: 0.4007 - val_loss: 0.8003 - val_mae: 0.4741 - val_mse: 0.3433\n",
      "Epoch 6/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.6399 - mae: 0.4518 - mse: 0.3097 - val_loss: 0.7405 - val_mae: 0.3448 - val_mse: 0.1986\n",
      "Epoch 7/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.5423 - mae: 0.3176 - mse: 0.1669 - val_loss: 0.7145 - val_mae: 0.3077 - val_mse: 0.1657\n",
      "Epoch 8/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.5193 - mae: 0.2916 - mse: 0.1449 - val_loss: 0.7114 - val_mae: 0.3014 - val_mse: 0.1586\n",
      "Epoch 9/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.5170 - mae: 0.2866 - mse: 0.1401 - val_loss: 0.7099 - val_mae: 0.3007 - val_mse: 0.1586\n",
      "Epoch 10/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.5130 - mae: 0.2860 - mse: 0.1390 - val_loss: 0.7096 - val_mae: 0.3008 - val_mse: 0.1582\n",
      "Epoch 11/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.5139 - mae: 0.2866 - mse: 0.1393 - val_loss: 0.7106 - val_mae: 0.2976 - val_mse: 0.1548\n",
      "Epoch 12/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.5168 - mae: 0.2863 - mse: 0.1393 - val_loss: 0.7091 - val_mae: 0.2991 - val_mse: 0.1558\n",
      "Epoch 13/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.5142 - mae: 0.2861 - mse: 0.1390 - val_loss: 0.7080 - val_mae: 0.2998 - val_mse: 0.1559\n",
      "Epoch 14/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.5120 - mae: 0.2863 - mse: 0.1391 - val_loss: 0.7092 - val_mae: 0.2985 - val_mse: 0.1549\n",
      "Epoch 15/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.5164 - mae: 0.2860 - mse: 0.1387 - val_loss: 0.7079 - val_mae: 0.2995 - val_mse: 0.1552\n",
      "Epoch 16/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.5141 - mae: 0.2858 - mse: 0.1389 - val_loss: 0.7077 - val_mae: 0.2998 - val_mse: 0.1557\n",
      "Epoch 17/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.5167 - mae: 0.2859 - mse: 0.1386 - val_loss: 0.7085 - val_mae: 0.3003 - val_mse: 0.1556\n",
      "Epoch 18/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.5136 - mae: 0.2862 - mse: 0.1386 - val_loss: 0.7087 - val_mae: 0.2999 - val_mse: 0.1568\n",
      "Epoch 19/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.5153 - mae: 0.2872 - mse: 0.1398 - val_loss: 0.7090 - val_mae: 0.2995 - val_mse: 0.1554\n",
      "Epoch 20/20\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.5161 - mae: 0.2876 - mse: 0.1401 - val_loss: 0.7080 - val_mae: 0.2995 - val_mse: 0.1557\n",
      "0.7076647877693176\n"
     ]
    }
   ],
   "source": [
    "model_va=tf.keras.Model(inputs=img, outputs=va_out)\n",
    "model_va.compile(optimizer=Adam(lr=1e-3), loss=CCC_VA, metrics=['mae','mse'])\n",
    "model_va.summary()\n",
    "\n",
    "save_best_model = SaveBestModel('val_loss',False)\n",
    "model_va.fit(X_va_only_train,y_va_only_train, batch_size=batch_size, epochs=(8 if TRAIN_VAL else 20), verbose=1, callbacks=[save_best_model], \n",
    "          validation_data=(X_va_only_val,y_va_only_val))\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ccc():\n",
    "    _,y_val_preds,_=mtl_model_new.predict(X_val)\n",
    "    pred_V=y_val_preds[masks_va_val==1,0]\n",
    "    pred_A=y_val_preds[masks_va_val==1,1]\n",
    "    gt_V=y_va_only_val[:,0]\n",
    "    gt_A=y_va_only_val[:,1]\n",
    "    print(metric_for_VA(gt_V,gt_A,pred_V,pred_A))\n",
    "    print(CCC_numpy(gt_V,pred_V),CCC_numpy(gt_A,pred_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4640283582877984, 0.4195844716777797, 0.44180641498278905)\n",
      "0.4640456021571796 0.41960007897731355\n",
      "Best weights:\n",
      "(0.462840615766619, 0.4192827615479205, 0.44106168865726975)\n",
      "0.4628578275639917 0.41929834856504755\n"
     ]
    }
   ],
   "source": [
    "if not TRAIN_VAL:\n",
    "    print_ccc()\n",
    "    print('Best weights:')\n",
    "    model_va.set_weights(best_model_weights)\n",
    "print_ccc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features only\n",
    "(0.44702991590919305, 0.3999768085100121, 0.4235033622096026)\n",
    "0.4470465505604636 0.39999170544933943\n",
    "\n",
    "scores only\n",
    "(0.4678666794930614, 0.41790110240886674, 0.44288389095096403)\n",
    "0.4678840728855078 0.4179166374299864\n",
    "\n",
    "scores+features\n",
    "(0.4471655368461229, 0.4057897961501993, 0.4264776664981611)\n",
    "0.4471821561384188 0.4058049134330271\n",
    "Best weights:\n",
    "(0.4290930580201086, 0.40585204778442285, 0.4174725529022657)\n",
    "0.42910903221993124 0.4058671776723511"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1290)]            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               165248    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 166,796\n",
      "Trainable params: 166,796\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.4855 - auc: 0.8428 - binary_accuracy: 0.7752 - recall: 0.7436 - precision: 0.5025 - val_loss: 0.5610 - val_auc: 0.8030 - val_binary_accuracy: 0.7618 - val_recall: 0.7206 - val_precision: 0.5187\n",
      "Epoch 2/10\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3505 - auc: 0.9229 - binary_accuracy: 0.8491 - recall: 0.8108 - precision: 0.6238 - val_loss: 0.5850 - val_auc: 0.8057 - val_binary_accuracy: 0.7797 - val_recall: 0.7027 - val_precision: 0.5479\n",
      "Epoch 3/10\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3196 - auc: 0.9355 - binary_accuracy: 0.8625 - recall: 0.8279 - precision: 0.6511 - val_loss: 0.5899 - val_auc: 0.8099 - val_binary_accuracy: 0.7899 - val_recall: 0.7148 - val_precision: 0.5646\n",
      "Epoch 4/10\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.3000 - auc: 0.9429 - binary_accuracy: 0.8707 - recall: 0.8375 - precision: 0.6670 - val_loss: 0.6239 - val_auc: 0.8072 - val_binary_accuracy: 0.7988 - val_recall: 0.6819 - val_precision: 0.5854\n",
      "Epoch 5/10\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.2859 - auc: 0.9477 - binary_accuracy: 0.8766 - recall: 0.8441 - precision: 0.6807 - val_loss: 0.6222 - val_auc: 0.8048 - val_binary_accuracy: 0.7900 - val_recall: 0.7040 - val_precision: 0.5659\n",
      "Epoch 6/10\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.2759 - auc: 0.9505 - binary_accuracy: 0.8808 - recall: 0.8476 - precision: 0.6888 - val_loss: 0.6348 - val_auc: 0.8074 - val_binary_accuracy: 0.7990 - val_recall: 0.7021 - val_precision: 0.5830\n",
      "Epoch 7/10\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.2639 - auc: 0.9544 - binary_accuracy: 0.8852 - recall: 0.8555 - precision: 0.6983 - val_loss: 0.6492 - val_auc: 0.8019 - val_binary_accuracy: 0.7982 - val_recall: 0.6996 - val_precision: 0.5818\n",
      "Epoch 8/10\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.2563 - auc: 0.9569 - binary_accuracy: 0.8882 - recall: 0.8603 - precision: 0.7051 - val_loss: 0.6900 - val_auc: 0.8029 - val_binary_accuracy: 0.8092 - val_recall: 0.6930 - val_precision: 0.6049\n",
      "Epoch 9/10\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.2490 - auc: 0.9588 - binary_accuracy: 0.8917 - recall: 0.8619 - precision: 0.7125 - val_loss: 0.7200 - val_auc: 0.7968 - val_binary_accuracy: 0.8138 - val_recall: 0.6814 - val_precision: 0.6171\n",
      "Epoch 10/10\n",
      "202/202 [==============================] - 2s 8ms/step - loss: 0.2446 - auc: 0.9602 - binary_accuracy: 0.8938 - recall: 0.8645 - precision: 0.7173 - val_loss: 0.6963 - val_auc: 0.7978 - val_binary_accuracy: 0.7976 - val_recall: 0.7014 - val_precision: 0.5804\n",
      "0.5609792470932007\n"
     ]
    }
   ],
   "source": [
    "model_au=tf.keras.Model(inputs=img, outputs=aus_out)\n",
    "model_au.compile(optimizer=Adam(lr=1e-3), loss=loss_aus, metrics=metrics)\n",
    "model_au.summary()\n",
    "\n",
    "save_best_model = SaveBestModel('val_loss',False)\n",
    "model_au.fit(X_au_only_train,y_au_only_train, batch_size=batch_size, epochs=(3 if TRAIN_VAL else 10), verbose=1, callbacks=[save_best_model], \n",
    "          validation_data=(X_au_only_val,y_au_only_val))\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_au():\n",
    "    _,_,y_val_preds=mtl_model_new.predict(X_val)\n",
    "    y_val_preds=y_val_preds[masks_va_val==1,:]\n",
    "    new_pred = ((y_val_preds >= 0.5) * 1)\n",
    "    print(np.mean([f1_score(y_true=y_au_only_val[:,i],y_pred=new_pred[:,i]) for i in range(y_val_preds.shape[1])]))\n",
    "    print(f1_score_max(y_au_only_val,y_val_preds,thresh=np.arange(0.1,1,0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.493053875926913\n",
      "(0.512953298361032, 0.55, array([0.57497415, 0.42757318, 0.58180434, 0.59515843, 0.73442735,\n",
      "       0.70933747, 0.65871455, 0.2402863 , 0.2105919 , 0.17330046,\n",
      "       0.87640603, 0.37286542]), array([0.6, 0.8, 0.3, 0.3, 0.4, 0.5, 0.6, 0.8, 0.9, 0.4, 0.2, 0.8]), array([0.81649055, 0.8872228 , 0.79561691, 0.69385325, 0.71096889,\n",
      "       0.73522846, 0.79985861, 0.94470903, 0.95285757, 0.91267302,\n",
      "       0.79762613, 0.8510567 ]))\n",
      "Best weights:\n",
      "0.4840685140661731\n",
      "(0.5209951567187995, 0.6166666666666666, array([0.58488206, 0.46218487, 0.58164797, 0.61660118, 0.73464316,\n",
      "       0.71510358, 0.67256086, 0.23215686, 0.17610619, 0.22811918,\n",
      "       0.88039045, 0.36754551]), array([0.7, 0.8, 0.6, 0.4, 0.4, 0.4, 0.6, 0.9, 0.8, 0.8, 0.2, 0.8]), array([0.82713201, 0.89045989, 0.82374609, 0.70955499, 0.70602024,\n",
      "       0.71855931, 0.80432356, 0.96357345, 0.93071886, 0.93830927,\n",
      "       0.80577467, 0.85005209]))\n"
     ]
    }
   ],
   "source": [
    "if not TRAIN_VAL:\n",
    "    print_au()\n",
    "    print('Best weights:')\n",
    "    model_au.set_weights(best_model_weights)\n",
    "print_au()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features only\n",
    "0.4877955052186667\n",
    "(0.5189570784821854, 0.5833333333333334, array([0.58116199, 0.45216079, 0.57108141, 0.61143747, 0.73423989,\n",
    "       0.71524042, 0.67407235, 0.24712644, 0.18706157, 0.21825599,\n",
    "       0.87847458, 0.35717205]), array([0.6, 0.8, 0.5, 0.4, 0.4, 0.5, 0.5, 0.8, 0.8, 0.8, 0.2, 0.7]), array([0.81518827, 0.89198541, 0.80298408, 0.71204792, 0.70840155,\n",
    "       0.73999107, 0.79148683, 0.95125763, 0.92238428, 0.94296026,\n",
    "       0.80056556, 0.82441584]))\n",
    "\n",
    "\n",
    "scores only\n",
    "0.45390063440662276\n",
    "(0.48795630442917454, 0.6083333333333335, array([0.54249909, 0.41938422, 0.58782223, 0.55747069, 0.71403767,\n",
    "       0.69672571, 0.66193509, 0.12175394, 0.09201389, 0.23825503,\n",
    "       0.87423195, 0.34934614]), array([0.7, 0.8, 0.7, 0.4, 0.4, 0.5, 0.5, 0.8, 0.7, 0.9, 0.2, 0.7]), array([0.81254651, 0.88141837, 0.83401548, 0.67137967, 0.68135139,\n",
    "       0.72670784, 0.79264027, 0.92324007, 0.92216104, 0.93243042,\n",
    "       0.79360768, 0.81857419]))\n",
    "Best weights:\n",
    "0.4537206686412025\n",
    "(0.4870261851387019, 0.5916666666666667, array([0.5471062 , 0.42240552, 0.5691379 , 0.55744759, 0.72267255,\n",
    "       0.69784564, 0.66115412, 0.11682172, 0.08278146, 0.24589348,\n",
    "       0.87535587, 0.34569218]), array([0.7, 0.8, 0.7, 0.4, 0.4, 0.5, 0.5, 0.6, 0.7, 0.9, 0.2, 0.7]), array([0.82006251, 0.88796696, 0.83003423, 0.64027385, 0.69575086,\n",
    "       0.73124721, 0.78501265, 0.78452895, 0.91754725, 0.94363   ,\n",
    "       0.79148683, 0.81745796]))\n",
    "       \n",
    "\n",
    "scores+features\n",
    "0.4858337764396418\n",
    "(0.5187352880665755, 0.6166666666666667, array([0.58193373, 0.45640637, 0.56947413, 0.59397876, 0.73822173,\n",
    "       0.71687038, 0.66788597, 0.25583982, 0.1667372 , 0.2451184 ,\n",
    "       0.88012497, 0.352232  ]), array([0.7, 0.8, 0.6, 0.4, 0.5, 0.5, 0.6, 0.8, 0.7, 0.8, 0.2, 0.8]), array([0.82865754, 0.89328769, 0.81265813, 0.70695044, 0.7213127 ,\n",
    "       0.73798184, 0.8040631 , 0.95021581, 0.92673761, 0.93239321,\n",
    "       0.80298408, 0.85206132]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    #mtl_model_new.save_weights('mtl_enet0_separate.h5') #0.4416453346692747 0.338425880038155 0.4892950104555161 1.2693662251629458\n",
    "    mtl_model_new.save_weights('mtl_enet0_slice.h5') #0.4470512345513264 0.33507035885799447 0.4943377041019861 1.276459297511307\n",
    "else:\n",
    "    mtl_model_new.load_weights('../../../emotions-multimodal/faces/ABAW/abaw4/'+'mtl_enet0_slice.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VA\n",
      "(26876,) 0.4749176554355453 0.41918481366710747 0.4470512345513264\n",
      "\n",
      "Expression\n",
      "(15440,)\n",
      "0.35174870466321245\n",
      "0.33507035885799447\n",
      "(0.33507035885799447, 0.35174870466321245, [0.3309143686502177, 0.21268097853220172, 0.4306987399770905, 0.2674139311449159, 0.4919247295895688, 0.45335129673290675, 0.17721518987341772, 0.31636363636363635])\n",
      "\n",
      "AUs\n",
      "(26876, 12)\n",
      "0.4943377041019861 [0.5768960399906272, 0.4068865816795899, 0.5824795488841237, 0.5856791309045075, 0.7315399891677198, 0.7165887948815086, 0.6772090777402222, 0.1664488017429194, 0.12901334115232369, 0.17010197439791713, 0.8462372811321728, 0.34297188755020075]\n",
      "(0.5217870390537378, 0.5583333333333335, array([0.58350767, 0.46639283, 0.58247955, 0.60487214, 0.73661289,\n",
      "       0.71948443, 0.67720908, 0.25145518, 0.18346774, 0.2108389 ,\n",
      "       0.88044481, 0.36467925]), array([0.6, 0.7, 0.5, 0.3, 0.4, 0.4, 0.5, 0.9, 0.8, 0.7, 0.2, 0.7]), array([0.82222057, 0.89365977, 0.80439798, 0.68436523, 0.70296919,\n",
      "       0.72953565, 0.80101206, 0.95215062, 0.93972317, 0.92089597,\n",
      "       0.80238875, 0.84339187]))\n",
      "\n",
      "Total 0.4470512345513264 0.33507035885799447 0.4943377041019861 1.276459297511307\n"
     ]
    }
   ],
   "source": [
    "y_pred_expr,y_pred_va,y_pred_aus=mtl_model_new.predict(X_val)\n",
    "print('\\nVA')\n",
    "gt_V=y_va_val[masks_va_val==1,0]\n",
    "gt_A=y_va_val[masks_va_val==1,1]\n",
    "pred_V=y_pred_va[masks_va_val==1,0]\n",
    "pred_A=y_pred_va[masks_va_val==1,1]\n",
    "ccc_V,ccc_A,ccc_VA=metric_for_VA(gt_V,gt_A,pred_V,pred_A)\n",
    "print(gt_V.shape,ccc_V,ccc_A,ccc_VA)\n",
    "\n",
    "print('\\nExpression')\n",
    "print(y_expr_val[masks_expr_val==1].shape)\n",
    "y_pred=np.argmax(y_pred_expr,axis=1)\n",
    "print((y_pred==y_expr_val)[masks_expr_val==1].mean())\n",
    "f1_expr=f1_score(y_true=y_expr_val[masks_expr_val==1],y_pred=y_pred[masks_expr_val==1], average=\"macro\")\n",
    "print(f1_expr)\n",
    "print(metric_for_Exp(y_expr_val[masks_expr_val==1],y_pred[masks_expr_val==1]))\n",
    "\n",
    "print('\\nAUs')\n",
    "new_pred = ((y_pred_aus >= 0.5) * 1)\n",
    "print(new_pred[masks_aus_val==1,:].shape)\n",
    "f1_per_au=[f1_score(y_true=y_aus_val[masks_aus_val==1,i],y_pred=new_pred[masks_aus_val==1,i]) for i in range(y_pred_aus.shape[1])]\n",
    "f1_au=np.mean(f1_per_au)\n",
    "print(f1_au,f1_per_au)\n",
    "print(f1_score_max(y_aus_val[masks_aus_val==1,:],y_pred_aus[masks_aus_val==1,:],thresh=np.arange(0.1,1,0.1)))\n",
    "\n",
    "total=ccc_VA+f1_expr+f1_au\n",
    "print('\\nTotal',ccc_VA,f1_expr,f1_au,total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features only\n",
    "Total 0.4235033622096026 0.33853939646012643 0.4877955052186667 1.2498382638883958\n",
    "\n",
    "scores only\n",
    "Total 0.44288389095096403 0.2605997985451292 0.4537206686412025 1.1572043581372957\n",
    "\n",
    "scores+features\n",
    "0.4174725529022657 0.3334845842529065 0.4858337764396418 1.236790913594814"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenFace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/HDD6TB/datasets/emotions/ABAW/eccv_4/cropped_aligned /home/HDD6TB/datasets/emotions/ABAW/eccv_4/openface_aus_cropped_aligned\n"
     ]
    }
   ],
   "source": [
    "data_dir=DATA_DIR / 'cropped_aligned'\n",
    "#outdir=DATA_DIR / 'openface_cropped_aligned'\n",
    "outdir=DATA_DIR / 'openface_aus_cropped_aligned'\n",
    "test_data_dir=DATA_DIR / 'mtl_test_data/cropped_aligned'\n",
    "test_outdir=DATA_DIR / 'mtl_test_data/openface_aus_cropped_aligned'\n",
    "\n",
    "if False:#Test\n",
    "    data_dir=test_data_dir\n",
    "    outdir=test_outdir\n",
    "print(data_dir,outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/avsavchenko/src/distr/OpenFace/build/bin/FeatureExtraction -aus -out_dir /home/HDD6TB/datasets/emotions/ABAW/eccv_4/mtl_test_data/openface_aus_cropped_aligned -fdir video32 -fdir video17 -fdir 197 -fdir video21 -fdir video5_right -fdir 171 -fdir 199 -fdir video45_4 -fdir 134-30-1280x720 -fdir 241 -fdir 204 -fdir video12 -fdir video53 -fdir video26 -fdir video5_left -fdir video33 -fdir video13 -fdir 286 -fdir 322 -fdir video22 -fdir video39 -fdir video35 -fdir video20 -fdir 274 -fdir 14-30-1920x1080 -fdir 130-25-1280x720_left -fdir 219 -fdir 270 -fdir video51 -fdir video45_1 -fdir video45_2 -fdir 234 -fdir video37 -fdir 304 -fdir video38 -fdir video29_right -fdir video46 -fdir video30 -fdir 49-30-1280x720_right -fdir 212 -fdir 40-30-1280x720 -fdir 265 -fdir video11 -fdir 267 -fdir video19 -fdir video23 -fdir video42 -fdir video25 -fdir video16 -fdir video49_right -fdir video9 -fdir video40 -fdir 239 -fdir 194 -fdir video44 -fdir 281 -fdir 313 -fdir 284 -fdir 130-25-1280x720_right -fdir 43-30-406x720 -fdir video52 -fdir video10_1_left -fdir video27 -fdir 303 -fdir 244 -fdir video15 -fdir 307 -fdir 209 -fdir video65 -fdir 55-25-1280x720 -fdir 289 -fdir 311 -fdir video18 -fdir video29_left -fdir video36 -fdir video14 -fdir video28 -fdir 268 -fdir 49-30-1280x720_left -fdir video41 -fdir 266 -fdir video10_1_right\n",
      "/home/HDD6TB/avsavchenko/src/emotions-multimodal/faces/ABAW/abaw4\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "cur_dir=os.getcwd()\n",
    "os.chdir(data_dir)\n",
    "#command='/home/avsavchenko/src/distr/OpenFace/build/bin/FeatureExtraction -pose -aus -gaze -out_dir '+str(outdir)\n",
    "command='/home/avsavchenko/src/distr/OpenFace/build/bin/FeatureExtraction -aus -out_dir '+str(outdir)\n",
    "for filename in os.listdir('.'):\n",
    "    if os.path.isdir(filename):\n",
    "        command+=' -fdir '+filename\n",
    "\n",
    "print(command)\n",
    "os.system(command=command)\n",
    "\n",
    "os.chdir(cur_dir)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133568, 35) (133568, 2) (133568,) (133568, 12) (133568,) (133568,) 0 133568 8765\n",
      "(26876, 35) (26876, 2) (26876,) (26876, 12) (26876,) (26876,) 0 25796 1080\n"
     ]
    }
   ],
   "source": [
    "def get_openface_features(filename,success_only=True):\n",
    "    with open(DATA_DIR / filename) as f:\n",
    "        mtl_lines = f.read().splitlines()\n",
    "    num_missed=num_fails=0\n",
    "    X,y_va,y_expr,y_aus=[],[],[],[]\n",
    "    masks_va,masks_expr,masks_aus=[],[],[]\n",
    "    mask_success=[]\n",
    "    \n",
    "    prev_videoname=''\n",
    "    video_frames=None\n",
    "    \n",
    "    for line in mtl_lines[1:]:\n",
    "        splitted_line=line.split(',')\n",
    "        imagename=splitted_line[0]\n",
    "        valence=float(splitted_line[1])\n",
    "        arousal=float(splitted_line[2])\n",
    "        expression=int(splitted_line[3])\n",
    "        aus=list(map(int,splitted_line[4:]))\n",
    "        \n",
    "        mask_VA=(valence>-5 and arousal>-5)\n",
    "        if not mask_VA:\n",
    "            valence=arousal=0\n",
    "            \n",
    "        mask_expr=(expression>-1)\n",
    "        if not mask_expr:\n",
    "            expression=0\n",
    "            \n",
    "        mask_aus=min(aus)>=0\n",
    "        if not mask_aus:\n",
    "            aus=[0]*len(aus)\n",
    "        #print(imagename,valence,arousal,expression,aus)\n",
    "        if mask_VA or mask_expr or mask_aus:\n",
    "            videoname,filename=imagename.split('/')\n",
    "            if videoname!=prev_videoname:\n",
    "                fpath=outdir / (videoname+'.csv')\n",
    "                if os.path.exists(fpath):\n",
    "                    df = pd.read_csv(fpath)\n",
    "                    success=(df.success==1).to_numpy()\n",
    "                    df = df.drop(columns=['frame', 'face_id','timestamp', 'confidence', 'success'])\n",
    "                    df=df.drop(columns=[c for c in df.columns if c.startswith('eye')])\n",
    "                    df=df.drop(columns=[c for c in df.columns if c.startswith('gaze')])\n",
    "                    #df=df.drop(columns=[c for c in df.columns if c.startswith('AU')])\n",
    "                    df=df.drop(columns=[c for c in df.columns if c.startswith('pose')])\n",
    "                    cur_features=df.to_numpy()\n",
    "                    \n",
    "                    video_frames={f:i for i,f in enumerate(sorted(os.listdir(data_dir / videoname)))}\n",
    "                    #print(videoname,cur_features.shape,len(video_frames))\n",
    "                    prev_videoname=videoname\n",
    "                \n",
    "            if video_frames is not None and filename in video_frames:\n",
    "                ind=video_frames[filename]\n",
    "                if not success_only or success[ind]==1:\n",
    "                    mask_success.append(success[ind])\n",
    "                    X.append(cur_features[ind])\n",
    "                    y_va.append((valence,arousal))\n",
    "                    masks_va.append(mask_VA)\n",
    "\n",
    "                    y_expr.append(expression)\n",
    "                    masks_expr.append(mask_expr)\n",
    "\n",
    "                    y_aus.append(aus)\n",
    "                    masks_aus.append(mask_aus)\n",
    "                if not success[ind]:\n",
    "                    num_fails+=1\n",
    "            else:\n",
    "                num_missed+=1\n",
    "        #elif (valence==-5 or arousal==-5) and valence!=arousal:\n",
    "        #    print(valence,arousal)\n",
    "    X=np.array(X)\n",
    "    y_va=np.array(y_va)\n",
    "    y_expr=np.array(y_expr)\n",
    "    y_aus=np.array(y_aus)\n",
    "    masks_va=np.array(masks_va).astype(np.float32)\n",
    "    masks_expr=np.array(masks_expr).astype(np.float32)\n",
    "    masks_aus=np.array(masks_aus).astype(np.float32)\n",
    "    mask_success=np.array(mask_success)\n",
    "    print(X.shape,y_va.shape,y_expr.shape,y_aus.shape,masks_va.shape,mask_success.shape,num_missed,mask_success.sum(),num_fails)\n",
    "    return X,y_va,y_expr,y_aus,masks_va,masks_expr,masks_aus,mask_success\n",
    "\n",
    "X_of_train,y_of_va_train,y_of_expr_train,y_of_aus_train,masks_of_va_train,masks_of_expr_train,masks_of_aus_train,_=get_openface_features('training_set_annotations.txt',success_only=True)\n",
    "X_of_val_all,y_of_va_val_all,y_of_expr_val_all,y_of_aus_val_all,masks_of_va_val_all,masks_of_expr_val_all,masks_of_aus_val_all,masks_val_success=get_openface_features('validation_set_annotations.txt',success_only=False)\n",
    "X_of_val,y_of_va_val,y_of_expr_val,y_of_aus_val,masks_of_va_val,masks_of_expr_val,masks_of_aus_val=X_of_val_all[masks_val_success],y_of_va_val_all[masks_val_success],y_of_expr_val_all[masks_val_success],y_of_aus_val_all[masks_val_success],masks_of_va_val_all[masks_val_success],masks_of_expr_val_all[masks_val_success],masks_of_aus_val_all[masks_val_success]\n",
    "TRAIN_VAL=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84573, 35) (84573,) (14717, 35) (14717,)\n",
      "(97977, 35) (97977, 2) (25796, 35) (25796, 2)\n",
      "(97376, 35) (97376, 12) (25796, 35) (25796, 12)\n"
     ]
    }
   ],
   "source": [
    "X_of_expr_only_train,y_of_expr_only_train=X_of_train[masks_of_expr_train==1],y_of_expr_train[masks_of_expr_train==1]\n",
    "X_of_expr_only_val,y_of_expr_only_val=X_of_val[masks_of_expr_val==1],y_of_expr_val[masks_of_expr_val==1]\n",
    "print(X_of_expr_only_train.shape,y_of_expr_only_train.shape,X_of_expr_only_val.shape,y_of_expr_only_val.shape)\n",
    "\n",
    "X_of_va_only_train,y_of_va_only_train=X_of_train[masks_of_va_train==1],y_of_va_train[masks_of_va_train==1]\n",
    "X_of_va_only_val,y_of_va_only_val=X_of_val[masks_of_va_val==1],y_of_va_val[masks_of_va_val==1]\n",
    "print(X_of_va_only_train.shape,y_of_va_only_train.shape,X_of_va_only_val.shape,y_of_va_only_val.shape)\n",
    "\n",
    "X_of_au_only_train,y_of_au_only_train=X_of_train[masks_of_aus_train==1],y_of_aus_train[masks_of_aus_train==1]\n",
    "X_of_au_only_val,y_of_au_only_val=X_of_val[masks_of_aus_val==1],y_of_aus_val[masks_of_aus_val==1]\n",
    "print(X_of_au_only_train.shape,y_of_au_only_train.shape,X_of_au_only_val.shape,y_of_au_only_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22485  4335  3130  2720 16643  7202  4626 23432] {0: 1.0421169668668, 1: 5.405305651672434, 2: 7.486261980830671, 3: 8.614705882352942, 4: 1.4079192453283662, 5: 3.253540683143571, 6: 5.065283182014699, 7: 1.0} 8 [0 1 2 3 4 5 6 7]\n",
      "[1.04211697 5.40530565 7.48626198 8.61470588 1.40791925 3.25354068\n",
      " 5.06528318 1.        ]\n",
      "12\n",
      "0 79848 17528 [20491  5305]\n",
      "1 89126 8250 [23289  2507]\n",
      "2 78020 19356 [20659  5137]\n",
      "3 68420 28956 [17371  8425]\n",
      "4 58373 39003 [12913 12883]\n",
      "5 61589 35787 [14731 11065]\n",
      "6 71971 25405 [17663  8133]\n",
      "7 94982 2394 [25017   779]\n",
      "8 94445 2931 [25045   751]\n",
      "9 92583 4793 [25009   787]\n",
      "10 30861 66515 [ 6066 19730]\n",
      "11 87156 10220 [22915  2881]\n",
      "[[ 0.60975854  2.77772707]\n",
      " [ 0.54628279  5.90157576]\n",
      " [ 0.62404512  2.51539574]\n",
      " [ 0.71160479  1.68144771]\n",
      " [ 0.83408425  1.24831423]\n",
      " [ 0.79053078  1.36049403]\n",
      " [ 0.6764947   1.91647314]\n",
      " [ 0.51260239 20.33751044]\n",
      " [ 0.51551697 16.61139543]\n",
      " [ 0.52588488 10.1581473 ]\n",
      " [ 1.57765465  0.73198527]\n",
      " [ 0.5586305   4.76399217]]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_of_expr_only_train.astype(int), return_counts=True)\n",
    "num_classes=len(unique)\n",
    "emo_cw=1/counts\n",
    "#emo_cw*=counts.mean()\n",
    "emo_cw/=emo_cw.min()\n",
    "emo_class_weights = {i:cwi for i,cwi in zip(unique,emo_cw)}\n",
    "print(counts, emo_class_weights, num_classes, unique)\n",
    "print(emo_cw)\n",
    "\n",
    "\n",
    "num_labels=y_of_aus_train.shape[1]\n",
    "print(num_labels)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "aus_class_weights = np.empty([num_labels, 2])\n",
    "for i in range(num_labels):\n",
    "    neg, pos = np.bincount(y_of_au_only_train[:, i])\n",
    "    print(i,neg,pos,np.bincount(y_of_au_only_val[:, i]))\n",
    "    total = neg + pos\n",
    "    weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "    weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "    aus_class_weights[i][0]=weight_for_0\n",
    "    aus_class_weights[i][1]=weight_for_1\n",
    "    #aus_class_weights[i] = compute_class_weight('balanced', [0,1], y_train[:, i])\n",
    "print(aus_class_weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_va(y_true, y_pred):\n",
    "    res=1-0.5*(CCC(y_true[:,0], y_pred[:,0])+CCC(y_true[:,1], y_pred[:,1]))\n",
    "    #res=K.mean((y_true[:,0] - y_pred[:,0]) * (y_true[:,0] - y_pred[:,0]))+K.mean((y_true[:,1] - y_pred[:,1]) * (y_true[:,1] - y_pred[:,1]))\n",
    "    #print(res)\n",
    "    return res\n",
    "\n",
    "class WeightedExprSCCE(tf.keras.losses.Loss):\n",
    "    def __init__(self, class_weight, from_logits=False, name='expr_scce'):\n",
    "        if class_weight is None or all(v == 1. for v in class_weight):\n",
    "            self.class_weight = None\n",
    "        else:\n",
    "            self.class_weight = tf.convert_to_tensor(class_weight,\n",
    "                dtype=tf.float32)\n",
    "        self.reduction = tf.keras.losses.Reduction.NONE\n",
    "        self.unreduced_scce = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=from_logits, name=name,\n",
    "            reduction=self.reduction)\n",
    "\n",
    "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
    "        loss = self.unreduced_scce(y_true, y_pred, sample_weight)\n",
    "        if self.class_weight is not None:\n",
    "            weight_mask = tf.gather(self.class_weight, y_true)\n",
    "            loss = tf.math.multiply(loss, weight_mask)\n",
    "        loss=K.mean(loss)\n",
    "        return loss\n",
    "loss_expr=WeightedExprSCCE(emo_cw)\n",
    "\n",
    "\n",
    "\n",
    "def get_weighted_loss_aus(weights):\n",
    "    def weighted_loss(y_true, y_pred):\n",
    "        y_true=tf.cast(y_true, tf.float32)\n",
    "        ce=K.binary_crossentropy(y_true, y_pred)\n",
    "        res=K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*ce)#, axis=-1)\n",
    "        #print(res)\n",
    "        return res\n",
    "    return weighted_loss\n",
    "loss_aus=get_weighted_loss_aus(aus_class_weights)\n",
    "\n",
    "metrics=[tf.keras.metrics.AUC(multi_label=True,name='auc'), tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Recall(),tf.keras.metrics.Precision()] #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "batch_size=256 #128\n",
    "model_expr=Sequential()\n",
    "if False:\n",
    "    model_expr.add(Dense(num_classes, input_shape=X_of_train.shape[1:],activation='softmax',use_bias=True,kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size)))\n",
    "else:\n",
    "    model_expr.add(Dense(128, input_shape=X_of_train.shape[1:],activation='relu')) #256\n",
    "    model_expr.add(Dense(num_classes,activation='softmax'))\n",
    "    \n",
    "initial_weights=copy.deepcopy(model_expr.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 128)               4608      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 5,640\n",
      "Trainable params: 5,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "331/331 [==============================] - 1s 4ms/step - loss: 4.1472 - accuracy: 0.2664 - val_loss: 1.9916 - val_accuracy: 0.2615\n",
      "Epoch 2/10\n",
      "331/331 [==============================] - 1s 4ms/step - loss: 3.4199 - accuracy: 0.3742 - val_loss: 1.9665 - val_accuracy: 0.2772\n",
      "Epoch 3/10\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 3.1885 - accuracy: 0.4117 - val_loss: 1.9663 - val_accuracy: 0.2804\n",
      "Epoch 4/10\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 3.0185 - accuracy: 0.4379 - val_loss: 1.9928 - val_accuracy: 0.2772\n",
      "Epoch 5/10\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 2.8662 - accuracy: 0.4644 - val_loss: 2.0413 - val_accuracy: 0.2717\n",
      "Epoch 6/10\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 2.7739 - accuracy: 0.4805 - val_loss: 2.0617 - val_accuracy: 0.2732\n",
      "Epoch 7/10\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 2.6952 - accuracy: 0.4881 - val_loss: 2.0841 - val_accuracy: 0.2693\n",
      "Epoch 8/10\n",
      "331/331 [==============================] - 1s 4ms/step - loss: 2.6499 - accuracy: 0.4963 - val_loss: 2.1091 - val_accuracy: 0.2673\n",
      "Epoch 9/10\n",
      "331/331 [==============================] - 1s 4ms/step - loss: 2.6042 - accuracy: 0.5074 - val_loss: 2.1023 - val_accuracy: 0.2763\n",
      "Epoch 10/10\n",
      "331/331 [==============================] - 1s 4ms/step - loss: 2.5370 - accuracy: 0.5158 - val_loss: 2.1559 - val_accuracy: 0.2674\n",
      "0.2803560495376587\n"
     ]
    }
   ],
   "source": [
    "model_expr.set_weights(copy.deepcopy(initial_weights))\n",
    "model_expr.compile(optimizer=Adam(lr=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_expr.summary()\n",
    "\n",
    "save_best_model = SaveBestModel('val_accuracy',True)\n",
    "model_expr.fit(X_of_expr_only_train,y_of_expr_only_train, batch_size=batch_size, epochs=10, verbose=1, \n",
    "             callbacks=[save_best_model], validation_data=(X_of_expr_only_val,y_of_expr_only_val),class_weight=emo_class_weights)\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.267445810966909 F1: 0.24190535710143465\n",
      "(0.24190535710143465, 0.267445810966909, [0.24436826640548484, 0.15917525773195876, 0.2960482250502344, 0.15828677839851024, 0.39813474835182505, 0.1691542288557214, 0.20785969470607338, 0.3022156573116691])\n",
      "Best weights:\n",
      "Acc: 0.28035605082557585 F1: 0.2575082724838059\n",
      "(0.2575082724838059, 0.28035605082557585, [0.21838407494145198, 0.16407355021216405, 0.3193987787693753, 0.17784050811573748, 0.3757660654876554, 0.247171453437772, 0.22011661807580177, 0.33731513083048914])\n"
     ]
    }
   ],
   "source": [
    "def print_expr():\n",
    "    y_val_preds=model_expr.predict(X_of_expr_only_val)\n",
    "    y_pred=np.argmax(y_val_preds,axis=1)\n",
    "    print('Acc:',(y_pred==y_of_expr_only_val).mean(), 'F1:',f1_score(y_true=y_of_expr_only_val,y_pred=y_pred, average=\"macro\"))\n",
    "    print(metric_for_Exp(y_of_expr_only_val,y_pred))\n",
    "\n",
    "if True:\n",
    "    print_expr()\n",
    "    print('Best weights:')\n",
    "    model_expr.set_weights(best_model_weights)\n",
    "print_expr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eyes (280):\n",
    "Acc: 0.2779778487463478 F1: 0.07406295613044757\n",
    "(0.07406295613044757, 0.2779778487463478, [0.0, 0.0, 0.0, 0.0, 0.005359056806002143, 0.0, 0.13456362937331795, 0.45258096286426047])\n",
    "\n",
    "gaze (8):\n",
    "Acc: 0.16056261466331453 F1: 0.11271662722681726\n",
    "(0.11271662722681726, 0.16056261466331453, [0.0, 0.10371318822023047, 0.07899934167215274, 0.050259965337954945, 0.17420170723996203, 0.0851218624954529, 0.07574654042243263, 0.33369041242635245])\n",
    "\n",
    "AU(35):\n",
    "Acc: 0.29809064347353403 F1: 0.26092886553983147\n",
    "(0.26092886553983147, 0.29809064347353403, [0.2355798421372192, 0.19155844155844157, 0.2949579831932773, 0.07401177460050462, 0.47602686240824615, 0.2528344671201814, 0.24332909783989834, 0.31913245546088304])\n",
    "\n",
    "pose(6):\n",
    "Acc: 0.12638445335326493 F1: 0.08603602630991644\n",
    "(0.08603602630991644, 0.12638445335326493, [0.06047244094488188, 0.0257201646090535, 0.11429949360983842, 0.01775523145212429, 0.052318668252080855, 0.07452681388012618, 0.05972696245733788, 0.28346843527388854])\n",
    "\n",
    "all features\n",
    "Acc: 0.31528164707481143 F1: 0.19678978218884605\n",
    "(0.19678978218884605, 0.31528164707481143, [0.050495049504950484, 0.0, 0.1168032786885246, 0.008708272859216257, 0.42180634662327093, 0.2803946530872056, 0.2761535752025361, 0.4199570815450644])\n",
    "\n",
    "-eye\n",
    "Acc: 0.28735475980159 F1: 0.23708360924334548\n",
    "(0.23708360924334548, 0.28735475980159, [0.2883403361344538, 0.15083798882681565, 0.262343404568902, 0.06230769230769231, 0.4243018128368447, 0.06851119894598155, 0.2667564836645335, 0.3732699566615406])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=512 #128\n",
    "model_va=Sequential()\n",
    "if True:\n",
    "    model_va.add(Dense(2, input_shape=X_of_train.shape[1:],activation='tanh',use_bias=True,kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size)))\n",
    "else:\n",
    "    model_va.add(Dense(128, input_shape=X_of_train.shape[1:],activation='relu')) #256\n",
    "    model_va.add(Dense(2,activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 2)                 72        \n",
      "=================================================================\n",
      "Total params: 72\n",
      "Trainable params: 72\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "192/192 [==============================] - 2s 6ms/step - loss: 0.9100 - mae: 0.4381 - mse: 0.3077 - val_loss: 0.8424 - val_mae: 0.4137 - val_mse: 0.2826\n",
      "Epoch 2/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.7758 - mae: 0.3887 - mse: 0.2444 - val_loss: 0.8003 - val_mae: 0.3777 - val_mse: 0.2407\n",
      "Epoch 3/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.7113 - mae: 0.3512 - mse: 0.2025 - val_loss: 0.7906 - val_mae: 0.3611 - val_mse: 0.2244\n",
      "Epoch 4/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6843 - mae: 0.3321 - mse: 0.1834 - val_loss: 0.7881 - val_mae: 0.3530 - val_mse: 0.2176\n",
      "Epoch 5/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6727 - mae: 0.3255 - mse: 0.1777 - val_loss: 0.7892 - val_mae: 0.3518 - val_mse: 0.2168\n",
      "Epoch 6/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6665 - mae: 0.3223 - mse: 0.1744 - val_loss: 0.7888 - val_mae: 0.3513 - val_mse: 0.2169\n",
      "Epoch 7/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6661 - mae: 0.3220 - mse: 0.1742 - val_loss: 0.7915 - val_mae: 0.3536 - val_mse: 0.2181\n",
      "Epoch 8/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6679 - mae: 0.3243 - mse: 0.1772 - val_loss: 0.7940 - val_mae: 0.3570 - val_mse: 0.2226\n",
      "Epoch 9/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6653 - mae: 0.3247 - mse: 0.1775 - val_loss: 0.7928 - val_mae: 0.3538 - val_mse: 0.2194\n",
      "Epoch 10/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6677 - mae: 0.3246 - mse: 0.1776 - val_loss: 0.7927 - val_mae: 0.3552 - val_mse: 0.2202\n",
      "Epoch 11/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6654 - mae: 0.3243 - mse: 0.1775 - val_loss: 0.7940 - val_mae: 0.3576 - val_mse: 0.2226\n",
      "Epoch 12/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6655 - mae: 0.3261 - mse: 0.1792 - val_loss: 0.7937 - val_mae: 0.3563 - val_mse: 0.2214\n",
      "Epoch 13/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6697 - mae: 0.3256 - mse: 0.1784 - val_loss: 0.7932 - val_mae: 0.3557 - val_mse: 0.2211\n",
      "Epoch 14/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6657 - mae: 0.3248 - mse: 0.1777 - val_loss: 0.7926 - val_mae: 0.3571 - val_mse: 0.2234\n",
      "Epoch 15/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6640 - mae: 0.3258 - mse: 0.1790 - val_loss: 0.7947 - val_mae: 0.3565 - val_mse: 0.2213\n",
      "Epoch 16/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6652 - mae: 0.3250 - mse: 0.1776 - val_loss: 0.7939 - val_mae: 0.3562 - val_mse: 0.2212\n",
      "Epoch 17/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6659 - mae: 0.3259 - mse: 0.1786 - val_loss: 0.7933 - val_mae: 0.3569 - val_mse: 0.2228\n",
      "Epoch 18/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6645 - mae: 0.3260 - mse: 0.1788 - val_loss: 0.7924 - val_mae: 0.3571 - val_mse: 0.2231\n",
      "Epoch 19/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6679 - mae: 0.3269 - mse: 0.1800 - val_loss: 0.7933 - val_mae: 0.3578 - val_mse: 0.2228\n",
      "Epoch 20/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.6660 - mae: 0.3254 - mse: 0.1780 - val_loss: 0.7939 - val_mae: 0.3583 - val_mse: 0.2241\n",
      "0.7881137728691101\n"
     ]
    }
   ],
   "source": [
    "model_va.compile(optimizer=Adam(lr=1e-3), loss=CCC_VA, metrics=['mae','mse'])\n",
    "model_va.summary()\n",
    "\n",
    "save_best_model = SaveBestModel('val_loss',False)\n",
    "model_va.fit(X_of_va_only_train,y_of_va_only_train, batch_size=batch_size, epochs=20, verbose=1, callbacks=[save_best_model], \n",
    "          validation_data=(X_of_va_only_val,y_of_va_only_val))\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.19568500673045028, 0.27970677685538065, 0.23769589179291545)\n",
      "0.1956925946400336 0.27971762259751964\n",
      "Best weights:\n",
      "(0.1964146670054143, 0.289529188272769, 0.24297192763909164)\n",
      "0.1964222709818761 0.2895404014178175\n"
     ]
    }
   ],
   "source": [
    "def print_ccc():\n",
    "    y_val_preds=model_va.predict(X_of_va_only_val)\n",
    "    pred_V=y_val_preds[:,0]\n",
    "    pred_A=y_val_preds[:,1]\n",
    "    gt_V=y_of_va_only_val[:,0]\n",
    "    gt_A=y_of_va_only_val[:,1]\n",
    "    print(metric_for_VA(gt_V,gt_A,pred_V,pred_A))\n",
    "    print(CCC_numpy(gt_V,pred_V),CCC_numpy(gt_A,pred_A))\n",
    "\n",
    "if True:\n",
    "    print_ccc()\n",
    "    print('Best weights:')\n",
    "    model_va.set_weights(best_model_weights)\n",
    "print_ccc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gaze (8):\n",
    "(0.09609551544301502, 0.011424792370935246, 0.05376015390697513)\n",
    "0.09609923428389722 0.011425235917943427\n",
    "\n",
    "AU(35):\n",
    "(0.2091367671541376, 0.2882616356667487, 0.24869920141044313)\n",
    "0.20914486016768477 0.2882728101199038\n",
    "\n",
    "pose(6):\n",
    "(8.173267441818511e-06, 0.00012606241963503896, 6.711784353842874e-05)\n",
    "8.173584345890638e-06 0.00012606730310202639\n",
    "\n",
    "eyes/all:\n",
    "0.0 0.0\n",
    "\n",
    "-eyes:\n",
    "(0.1900476866797427, 0.2670194001668687, 0.2285335434233057)\n",
    "0.1900550573300604 0.2670297612825224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=512 #128\n",
    "model_au=Sequential()\n",
    "if False:\n",
    "    model_au.add(Dense(y_of_au_only_train.shape[1], input_shape=X_of_train.shape[1:],activation='sigmoid',use_bias=True,kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size)))\n",
    "else:\n",
    "    model_au.add(Dense(128, input_shape=X_of_train.shape[1:],activation='relu')) #256\n",
    "    model_au.add(Dense(y_of_au_only_train.shape[1],activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 128)               4608      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 6,156\n",
      "Trainable params: 6,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "191/191 [==============================] - 2s 8ms/step - loss: 0.6422 - auc: 0.6694 - binary_accuracy: 0.6173 - recall_1: 0.6387 - precision_1: 0.3247 - val_loss: 0.6407 - val_auc: 0.6982 - val_binary_accuracy: 0.6790 - val_recall_1: 0.6056 - val_precision_1: 0.4095\n",
      "Epoch 2/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.5669 - auc: 0.7702 - binary_accuracy: 0.7126 - recall_1: 0.6479 - precision_1: 0.4083 - val_loss: 0.6484 - val_auc: 0.6984 - val_binary_accuracy: 0.6943 - val_recall_1: 0.6024 - val_precision_1: 0.4266\n",
      "Epoch 3/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.5516 - auc: 0.7854 - binary_accuracy: 0.7253 - recall_1: 0.6540 - precision_1: 0.4242 - val_loss: 0.6480 - val_auc: 0.6978 - val_binary_accuracy: 0.6896 - val_recall_1: 0.6047 - val_precision_1: 0.4213\n",
      "Epoch 4/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.5470 - auc: 0.7915 - binary_accuracy: 0.7275 - recall_1: 0.6614 - precision_1: 0.4297 - val_loss: 0.6557 - val_auc: 0.6979 - val_binary_accuracy: 0.6874 - val_recall_1: 0.5983 - val_precision_1: 0.4180\n",
      "Epoch 5/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.5358 - auc: 0.8015 - binary_accuracy: 0.7331 - recall_1: 0.6695 - precision_1: 0.4374 - val_loss: 0.6568 - val_auc: 0.6968 - val_binary_accuracy: 0.6830 - val_recall_1: 0.6035 - val_precision_1: 0.4137\n",
      "Epoch 6/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.5281 - auc: 0.8084 - binary_accuracy: 0.7374 - recall_1: 0.6785 - precision_1: 0.4439 - val_loss: 0.6586 - val_auc: 0.6945 - val_binary_accuracy: 0.6875 - val_recall_1: 0.6030 - val_precision_1: 0.4187\n",
      "Epoch 7/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.5226 - auc: 0.8146 - binary_accuracy: 0.7422 - recall_1: 0.6818 - precision_1: 0.4494 - val_loss: 0.6678 - val_auc: 0.6936 - val_binary_accuracy: 0.6938 - val_recall_1: 0.5916 - val_precision_1: 0.4248\n",
      "Epoch 8/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.5172 - auc: 0.8173 - binary_accuracy: 0.7471 - recall_1: 0.6828 - precision_1: 0.4561 - val_loss: 0.6702 - val_auc: 0.6936 - val_binary_accuracy: 0.6885 - val_recall_1: 0.5910 - val_precision_1: 0.4185\n",
      "Epoch 9/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.5141 - auc: 0.8212 - binary_accuracy: 0.7484 - recall_1: 0.6869 - precision_1: 0.4586 - val_loss: 0.6729 - val_auc: 0.6908 - val_binary_accuracy: 0.6888 - val_recall_1: 0.5863 - val_precision_1: 0.4183\n",
      "Epoch 10/20\n",
      "191/191 [==============================] - 1s 6ms/step - loss: 0.5107 - auc: 0.8234 - binary_accuracy: 0.7495 - recall_1: 0.6907 - precision_1: 0.4594 - val_loss: 0.6761 - val_auc: 0.6908 - val_binary_accuracy: 0.6971 - val_recall_1: 0.6111 - val_precision_1: 0.4308\n",
      "Epoch 11/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.5052 - auc: 0.8273 - binary_accuracy: 0.7550 - recall_1: 0.6941 - precision_1: 0.4665 - val_loss: 0.6792 - val_auc: 0.6905 - val_binary_accuracy: 0.6928 - val_recall_1: 0.5995 - val_precision_1: 0.4246\n",
      "Epoch 12/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.5037 - auc: 0.8301 - binary_accuracy: 0.7544 - recall_1: 0.6973 - precision_1: 0.4681 - val_loss: 0.6826 - val_auc: 0.6900 - val_binary_accuracy: 0.6879 - val_recall_1: 0.5958 - val_precision_1: 0.4183\n",
      "Epoch 13/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.4981 - auc: 0.8327 - binary_accuracy: 0.7579 - recall_1: 0.6984 - precision_1: 0.4721 - val_loss: 0.6823 - val_auc: 0.6893 - val_binary_accuracy: 0.6869 - val_recall_1: 0.6064 - val_precision_1: 0.4185\n",
      "Epoch 14/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.4981 - auc: 0.8332 - binary_accuracy: 0.7575 - recall_1: 0.7023 - precision_1: 0.4712 - val_loss: 0.6956 - val_auc: 0.6870 - val_binary_accuracy: 0.6959 - val_recall_1: 0.5852 - val_precision_1: 0.4267\n",
      "Epoch 15/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.4924 - auc: 0.8369 - binary_accuracy: 0.7625 - recall_1: 0.7010 - precision_1: 0.4767 - val_loss: 0.6880 - val_auc: 0.6898 - val_binary_accuracy: 0.6949 - val_recall_1: 0.6128 - val_precision_1: 0.4284\n",
      "Epoch 16/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.4923 - auc: 0.8381 - binary_accuracy: 0.7609 - recall_1: 0.7072 - precision_1: 0.4773 - val_loss: 0.7028 - val_auc: 0.6861 - val_binary_accuracy: 0.7035 - val_recall_1: 0.5911 - val_precision_1: 0.4368\n",
      "Epoch 17/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.4885 - auc: 0.8405 - binary_accuracy: 0.7664 - recall_1: 0.7079 - precision_1: 0.4854 - val_loss: 0.6991 - val_auc: 0.6855 - val_binary_accuracy: 0.6919 - val_recall_1: 0.5890 - val_precision_1: 0.4223\n",
      "Epoch 18/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.4884 - auc: 0.8395 - binary_accuracy: 0.7626 - recall_1: 0.7068 - precision_1: 0.4783 - val_loss: 0.6980 - val_auc: 0.6869 - val_binary_accuracy: 0.6919 - val_recall_1: 0.6170 - val_precision_1: 0.4253\n",
      "Epoch 19/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.4871 - auc: 0.8421 - binary_accuracy: 0.7637 - recall_1: 0.7117 - precision_1: 0.4809 - val_loss: 0.7047 - val_auc: 0.6852 - val_binary_accuracy: 0.6976 - val_recall_1: 0.6006 - val_precision_1: 0.4303\n",
      "Epoch 20/20\n",
      "191/191 [==============================] - 1s 7ms/step - loss: 0.4849 - auc: 0.8423 - binary_accuracy: 0.7653 - recall_1: 0.7101 - precision_1: 0.4834 - val_loss: 0.7132 - val_auc: 0.6858 - val_binary_accuracy: 0.7071 - val_recall_1: 0.5806 - val_precision_1: 0.4406\n",
      "0.6407111883163452\n"
     ]
    }
   ],
   "source": [
    "model_au.compile(optimizer=Adam(lr=1e-3), loss=loss_aus, metrics=metrics)\n",
    "model_au.summary()\n",
    "\n",
    "save_best_model = SaveBestModel('val_loss',False)\n",
    "model_au.fit(X_of_au_only_train,y_of_au_only_train, batch_size=batch_size, epochs=20, verbose=1, callbacks=[save_best_model], \n",
    "          validation_data=(X_of_au_only_val,y_of_au_only_val))\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39647167474999107\n",
      "(0.4220559777042339, 0.5083333333333333, array([0.45014739, 0.33946897, 0.39683331, 0.5076999 , 0.6861697 ,\n",
      "       0.65142776, 0.58635382, 0.08401254, 0.07576493, 0.13638968,\n",
      "       0.86687881, 0.2835249 ]), array([0.6, 0.7, 0.4, 0.4, 0.3, 0.3, 0.5, 0.6, 0.7, 0.8, 0.1, 0.7]), array([0.75414793, 0.84280509, 0.62490309, 0.61335091, 0.61990231,\n",
      "       0.61811909, 0.72526748, 0.83008994, 0.85245775, 0.94158009,\n",
      "       0.76647542, 0.81877035]))\n",
      "Best weights:\n",
      "0.402943536240024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4285070719228661, 0.49166666666666653, array([0.47324988, 0.35777518, 0.38066586, 0.53532446, 0.68493814,\n",
      "       0.64668806, 0.59833856, 0.09717257, 0.07920792, 0.12415086,\n",
      "       0.86703449, 0.29753888]), array([0.6, 0.7, 0.4, 0.5, 0.3, 0.4, 0.5, 0.6, 0.6, 0.6, 0.1, 0.6]), array([0.77977206, 0.85094588, 0.52116607, 0.6682819 , 0.59625523,\n",
      "       0.6457978 , 0.71697162, 0.78461777, 0.75484571, 0.85505505,\n",
      "       0.76550628, 0.77760118]))\n"
     ]
    }
   ],
   "source": [
    "def print_au():\n",
    "    y_val_preds=model_au.predict(X_of_au_only_val)\n",
    "    new_pred = ((y_val_preds >= 0.5) * 1)\n",
    "    print(np.mean([f1_score(y_true=y_of_au_only_val[:,i],y_pred=new_pred[:,i]) for i in range(y_val_preds.shape[1])]))\n",
    "    print(f1_score_max(y_of_au_only_val,y_val_preds,thresh=np.arange(0.1,1,0.1)))\n",
    "\n",
    "print_au()\n",
    "if True:\n",
    "    print('Best weights:')\n",
    "    model_au.set_weights(best_model_weights)\n",
    "    print_au()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gaze (8):\n",
    "0.33700727040525874\n",
    "(0.37684445283245993, 0.375, array([0.3462248 , 0.22813971, 0.33352061, 0.50523492, 0.66614959,\n",
    "       0.60036353, 0.49285385, 0.09313233, 0.0717555 , 0.0844358 ,\n",
    "       0.86675746, 0.23356535]), array([0.3, 0.5, 0.3, 0.4, 0.1, 0.1, 0.5, 0.5, 0.6, 0.6, 0.1, 0.5]), array([0.24441774, 0.75841216, 0.21821213, 0.41378508, 0.49941851,\n",
    "       0.42894247, 0.48829276, 0.68518375, 0.75628004, 0.81756862,\n",
    "       0.76484726, 0.69266553]))\n",
    "\n",
    "eyes:\n",
    "0.3564600478556352\n",
    "(0.37960306981121555, 0.4083333333333334, array([0.36417588, 0.24914956, 0.33002594, 0.49272711, 0.67171943,\n",
    "       0.6007334 , 0.51602659, 0.09207805, 0.05743645, 0.05730099,\n",
    "       0.86672671, 0.25713672]), array([0.8, 0.6, 0.1, 0.3, 0.5, 0.3, 0.6, 0.4, 0.2, 0.1, 0.3, 0.7]), array([0.72588773, 0.75186075, 0.1990231 , 0.33350132, 0.54496821,\n",
    "       0.43018297, 0.49193673, 0.60858273, 0.04702279, 0.10203132,\n",
    "       0.7648085 , 0.73166382]))\n",
    "\n",
    "AUs(35):\n",
    "0.40392001046178416\n",
    "(0.42757883295563887, 0.5166666666666666, array([0.4655188 , 0.35727045, 0.38784565, 0.53174125, 0.68184941,\n",
    "       0.64406905, 0.59717051, 0.09542041, 0.07538192, 0.12864622,\n",
    "       0.86645997, 0.29957236]), array([0.6, 0.7, 0.4, 0.5, 0.4, 0.4, 0.6, 0.6, 0.6, 0.7, 0.1, 0.6]), array([0.77015816, 0.86052101, 0.5400062 , 0.66859203, 0.64095209,\n",
    "       0.62591099, 0.74833307, 0.7618623 , 0.71375407, 0.90967592,\n",
    "       0.7645759 , 0.75872228]))\n",
    "\n",
    "pose(6):\n",
    "0.3182604488687078\n",
    "(0.36707807907659173, 0.35833333333333334, array([0.34642003, 0.20899408, 0.33209402, 0.49288198, 0.6663384 ,\n",
    "       0.6003961 , 0.49011684, 0.08241402, 0.05686594, 0.06029628,\n",
    "       0.8667765 , 0.20134275]), array([0.5, 0.5, 0.1, 0.4, 0.4, 0.2, 0.4, 0.7, 0.2, 0.5, 0.1, 0.3]), array([0.59730191, 0.74089006, 0.1991394 , 0.33854086, 0.50089161,\n",
    "       0.42902   , 0.3690107 , 0.7807412 , 0.03430764, 0.57950845,\n",
    "       0.76488603, 0.11459141]))\n",
    "\n",
    "all features\n",
    "0.36418628630291255\n",
    "(0.4300552415494017, 0.47500000000000003, array([0.45422924, 0.35724585, 0.39790889, 0.53198421, 0.69472495,\n",
    "       0.65344145, 0.60027301, 0.09012674, 0.09273248, 0.10274914,\n",
    "       0.86794033, 0.31730661]), array([0.7, 0.8, 0.2, 0.5, 0.4, 0.3, 0.3, 0.7, 0.6, 0.2, 0.1, 0.9]), array([0.75062025, 0.86176151, 0.68747093, 0.63242363, 0.64374322,\n",
    "       0.64378198, 0.73891301, 0.77457745, 0.86497907, 0.79756551,\n",
    "       0.76767716, 0.76496356]))\n",
    "-eye\n",
    "0.4022962580787666\n",
    "(0.4261672537136978, 0.5083333333333333, array([0.47709188, 0.35737077, 0.33555226, 0.5395627 , 0.69240549,\n",
    "       0.65095143, 0.59304883, 0.09115419, 0.06979158, 0.14028469,\n",
    "       0.86769587, 0.29909734]), array([0.6, 0.7, 0.4, 0.5, 0.4, 0.4, 0.5, 0.7, 0.5, 0.6, 0.3, 0.5]), array([0.75798573, 0.84385176, 0.39250271, 0.63591254, 0.64358815,\n",
    "       0.61885564, 0.71313382, 0.72557761, 0.54841836, 0.80566755,\n",
    "       0.76977051, 0.77725229]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expression\n",
      "0.28035605082557585\n",
      "0.2575082724838059\n",
      "(0.2575082724838059, 0.28035605082557585, [0.21838407494145198, 0.16407355021216405, 0.3193987787693753, 0.17784050811573748, 0.3757660654876554, 0.247171453437772, 0.22011661807580177, 0.33731513083048914])\n"
     ]
    }
   ],
   "source": [
    "print('\\nExpression')\n",
    "y_of_val_preds_expr=model_expr.predict(X_of_val_all)\n",
    "success_expr=(masks_val_success[masks_of_expr_val_all==1]==1)\n",
    "y_pred=np.argmax(y_of_val_preds_expr,axis=1)\n",
    "print((y_pred==y_of_expr_val_all)[masks_of_expr_val_all==1][success_expr].mean())\n",
    "f1_expr=f1_score(y_true=y_of_expr_val_all[masks_of_expr_val_all==1][success_expr],\n",
    "                 y_pred=y_pred[masks_of_expr_val_all==1][success_expr], average=\"macro\")\n",
    "print(f1_expr)\n",
    "print(metric_for_Exp(y_of_expr_val_all[masks_of_expr_val_all==1][success_expr],y_pred[masks_of_expr_val_all==1][success_expr]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VA\n",
      "(25796,) 0.19641466700852012 0.2895291882595464 0.24297192763403325\n",
      "\n",
      "AUs\n",
      "0.402943536240024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4285070719228661, 0.49166666666666653, array([0.47324988, 0.35777518, 0.38066586, 0.53532446, 0.68493814,\n",
      "       0.64668806, 0.59833856, 0.09717257, 0.07920792, 0.12415086,\n",
      "       0.86703449, 0.29753888]), array([0.6, 0.7, 0.4, 0.5, 0.3, 0.4, 0.5, 0.6, 0.6, 0.6, 0.1, 0.6]), array([0.77977206, 0.85094588, 0.52116607, 0.6682819 , 0.59625523,\n",
      "       0.6457978 , 0.71697162, 0.78461777, 0.75484571, 0.85505505,\n",
      "       0.76550628, 0.77760118]))\n",
      "\n",
      "Total 0.24297192763403325 0.2571850139826878 0.402943536240024 0.9031004778567451\n"
     ]
    }
   ],
   "source": [
    "print('\\nVA')\n",
    "y_of_val_preds_va=model_va.predict(X_of_val_all)\n",
    "success_va=(masks_val_success[masks_of_va_val_all==1]==1)\n",
    "pred_V=y_of_val_preds_va[masks_of_va_val_all==1,0][success_va]\n",
    "pred_A=y_of_val_preds_va[masks_of_va_val_all==1,1][success_va]\n",
    "gt_V=y_of_va_val_all[masks_of_va_val_all==1,0][success_va]\n",
    "gt_A=y_of_va_val_all[masks_of_va_val_all==1,1][success_va]\n",
    "ccc_V,ccc_A,ccc_VA=metric_for_VA(gt_V,gt_A,pred_V,pred_A)\n",
    "print(gt_V.shape,ccc_V,ccc_A,ccc_VA)\n",
    "\n",
    "print('\\nAUs')\n",
    "y_of_val_preds_aus=model_au.predict(X_of_val_all)\n",
    "success_aus=(masks_val_success[masks_of_aus_val_all==1]==1)\n",
    "new_pred = ((y_of_val_preds_aus >= 0.5) * 1)\n",
    "f1_au=np.mean([f1_score(y_true=y_of_aus_val_all[masks_of_aus_val_all==1,i][success_aus],\n",
    "                        y_pred=new_pred[masks_of_aus_val_all==1,i][success_aus]) for i in range(y_of_val_preds_aus.shape[1])])\n",
    "print(f1_au)\n",
    "print(f1_score_max(y_of_aus_val_all[masks_of_aus_val_all==1][success_aus],\n",
    "                   y_of_val_preds_aus[masks_of_aus_val_all==1][success_aus],thresh=np.arange(0.1,1,0.1)))\n",
    "\n",
    "total=ccc_VA+f1_expr+f1_au\n",
    "print('\\nTotal',ccc_VA,f1_expr,f1_au,total)\n",
    "#Total 0.2419729432148961 0.2559140140366414 0.4024556551490766 0.9003426124006141"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26876,) (26876, 2) (26876, 12)\n",
      "(51159, 8) (51159, 2) (51159, 12)\n"
     ]
    }
   ],
   "source": [
    "print(y_of_expr_val_all.shape,y_of_va_val_all.shape,y_of_aus_val_all.shape)\n",
    "print(y_pred_expr.shape,y_pred_va.shape,y_pred_aus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VA\n",
      "(26876,) 0.4749176554355453 0.41918481366710747 0.4470512345513264\n",
      "\n",
      "Expression\n",
      "(15440,)\n",
      "0.35174870466321245\n",
      "0.33507035885799447\n",
      "(0.33507035885799447, 0.35174870466321245, [0.3309143686502177, 0.21268097853220172, 0.4306987399770905, 0.2674139311449159, 0.4919247295895688, 0.45335129673290675, 0.17721518987341772, 0.31636363636363635])\n",
      "\n",
      "AUs\n",
      "(26876, 12)\n",
      "0.4943377041019861\n",
      "(0.5217870390537378, 0.5583333333333335, array([0.58350767, 0.46639283, 0.58247955, 0.60487214, 0.73661289,\n",
      "       0.71948443, 0.67720908, 0.25145518, 0.18346774, 0.2108389 ,\n",
      "       0.88044481, 0.36467925]), array([0.6, 0.7, 0.5, 0.3, 0.4, 0.4, 0.5, 0.9, 0.8, 0.7, 0.2, 0.7]), array([0.82222057, 0.89365977, 0.80439798, 0.68436523, 0.70296919,\n",
      "       0.72953565, 0.80101206, 0.95215062, 0.93972317, 0.92089597,\n",
      "       0.80238875, 0.84339187]))\n",
      "\n",
      "Total 0.4470512345513264 0.33507035885799447 0.4943377041019861 1.276459297511307\n"
     ]
    }
   ],
   "source": [
    "y_pred_expr,y_pred_va,y_pred_aus=mtl_model_new.predict(X_val)\n",
    "print('\\nVA')\n",
    "gt_V=y_va_val[masks_va_val==1,0]\n",
    "gt_A=y_va_val[masks_va_val==1,1]\n",
    "pred_V=y_pred_va[masks_va_val==1,0]\n",
    "pred_A=y_pred_va[masks_va_val==1,1]\n",
    "ccc_V,ccc_A,ccc_VA=metric_for_VA(gt_V,gt_A,pred_V,pred_A)\n",
    "print(gt_V.shape,ccc_V,ccc_A,ccc_VA)\n",
    "\n",
    "print('\\nExpression')\n",
    "print(y_expr_val[masks_expr_val==1].shape)\n",
    "y_pred=np.argmax(y_pred_expr,axis=1)\n",
    "print((y_pred==y_expr_val)[masks_expr_val==1].mean())\n",
    "f1_expr=f1_score(y_true=y_expr_val[masks_expr_val==1],y_pred=y_pred[masks_expr_val==1], average=\"macro\")\n",
    "print(f1_expr)\n",
    "print(metric_for_Exp(y_expr_val[masks_expr_val==1],y_pred[masks_expr_val==1]))\n",
    "\n",
    "print('\\nAUs')\n",
    "new_pred = ((y_pred_aus >= 0.5) * 1)\n",
    "print(new_pred[masks_aus_val==1,:].shape)\n",
    "f1_au=np.mean([f1_score(y_true=y_aus_val[masks_aus_val==1,i],y_pred=new_pred[masks_aus_val==1,i]) for i in range(y_pred_aus.shape[1])])\n",
    "print(f1_au)\n",
    "print(f1_score_max(y_aus_val[masks_aus_val==1,:],y_pred_aus[masks_aus_val==1,:],thresh=np.arange(0.1,1,0.1)))\n",
    "\n",
    "total=ccc_VA+f1_expr+f1_au\n",
    "print('\\nTotal',ccc_VA,f1_expr,f1_au,total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 F1: 0.25134282824069276\n",
      "0.1 F1: 0.2719023289473588\n",
      "0.2 F1: 0.2900276546934521\n",
      "0.30000000000000004 F1: 0.31073224086083157\n",
      "0.4 F1: 0.3337807788288267\n",
      "0.5 F1: 0.34577055619286023\n",
      "0.6000000000000001 F1: 0.3542082155899847\n",
      "0.7000000000000001 F1: 0.3529213573033453\n",
      "0.8 F1: 0.3475036965122771\n",
      "0.9 F1: 0.34137692566502637\n",
      "1.0 F1: 0.33507035885799447\n"
     ]
    }
   ],
   "source": [
    "for w in np.linspace(0,1,11):\n",
    "    y_ensemble=w*y_pred_expr+(1-w)*y_of_val_preds_expr*masks_val_success.reshape((-1,1))\n",
    "    y_pred=np.argmax(y_ensemble,axis=1)\n",
    "    print(w,'F1:',f1_score(y_true=y_expr_val[masks_expr_val==1],y_pred=y_pred[masks_expr_val==1], average=\"macro\"))\n",
    "    #print(metric_for_Exp(gt_expr,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 (0.19709510723522208, 0.2679740589847627, 0.23253458310999237)\n",
      "0.1 (0.2379344957539207, 0.2953908004476591, 0.2666626481007899)\n",
      "0.2 (0.2792266606075017, 0.32254497367625407, 0.3008858171418779)\n",
      "0.30000000000000004 (0.31955003055339887, 0.3484370566448255, 0.33399354359911215)\n",
      "0.4 (0.35738971557552646, 0.3719672957954081, 0.3646785056854673)\n",
      "0.5 (0.39130832435371604, 0.3920499644862386, 0.3916791444199773)\n",
      "0.6000000000000001 (0.42011955414681934, 0.40775011202467965, 0.4139348330857495)\n",
      "0.7000000000000001 (0.44302349453844625, 0.418412368328051, 0.43071793143324866)\n",
      "0.8 (0.45967155771334955, 0.4237480756390997, 0.44170981667622466)\n",
      "0.9 (0.4701531162154282, 0.42385745288521887, 0.4470052845503235)\n",
      "1.0 (0.4749176554355453, 0.41918481366710747, 0.4470512345513264)\n"
     ]
    }
   ],
   "source": [
    "for w in np.linspace(0,1,11):\n",
    "    y_ensemble=w*y_pred_va+(1-w)*y_of_val_preds_va*masks_val_success.reshape((-1,1))\n",
    "    pred_V=y_ensemble[masks_va_val==1,0]\n",
    "    pred_A=y_ensemble[masks_va_val==1,1]\n",
    "    print(w,metric_for_VA(gt_V,gt_A,pred_V,pred_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.3971496320690291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.42292530848517046, 0.49166666666666653, array([0.46353646, 0.3549884 , 0.3749321 , 0.52413866, 0.67794479,\n",
      "       0.6379067 , 0.59227795, 0.09712522, 0.07913878, 0.12354312,\n",
      "       0.85395107, 0.29562044]), array([0.6, 0.7, 0.4, 0.5, 0.3, 0.4, 0.5, 0.6, 0.6, 0.6, 0.1, 0.6]), array([0.78021283, 0.85518678, 0.52905938, 0.66698914, 0.59979164,\n",
      "       0.64678524, 0.72142432, 0.79316118, 0.76447388, 0.86009823,\n",
      "       0.74899539, 0.78456616])) \n",
      "\n",
      "0.1 0.4160251550983128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4406446590884676, 0.5166666666666666, array([0.4819551 , 0.37936652, 0.42602524, 0.53284592, 0.69070407,\n",
      "       0.65544872, 0.6073531 , 0.10666667, 0.09787088, 0.14114441,\n",
      "       0.85532522, 0.31303007]), array([0.6, 0.7, 0.5, 0.5, 0.4, 0.4, 0.5, 0.6, 0.6, 0.6, 0.2, 0.6]), array([0.7965099 , 0.87241405, 0.72920077, 0.68142581, 0.66933323,\n",
      "       0.6640125 , 0.73694002, 0.80555142, 0.8045096 , 0.88272064,\n",
      "       0.75461378, 0.80108647])) \n",
      "\n",
      "0.2 0.43793591072827615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.46096259292810443, 0.49166666666666653, array([0.50423925, 0.39517228, 0.49463627, 0.54864449, 0.70966629,\n",
      "       0.66905679, 0.62069356, 0.11856418, 0.11599006, 0.1680831 ,\n",
      "       0.86067095, 0.32613391]), array([0.5, 0.7, 0.5, 0.4, 0.4, 0.4, 0.5, 0.6, 0.6, 0.6, 0.1, 0.6]), array([0.76067867, 0.884395  , 0.77563626, 0.64008781, 0.68696979,\n",
      "       0.6771469 , 0.7509302 , 0.8190951 , 0.84119661, 0.90165947,\n",
      "       0.75692067, 0.81425807])) \n",
      "\n",
      "0.30000000000000004 0.4590171416311466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.47987252887762133, 0.5249999999999999, array([0.53451692, 0.41157025, 0.55286983, 0.56354172, 0.72101833,\n",
      "       0.68479009, 0.63436008, 0.13264059, 0.13313462, 0.18889282,\n",
      "       0.86509932, 0.33603578]), array([0.5, 0.7, 0.5, 0.4, 0.4, 0.4, 0.6, 0.7, 0.6, 0.6, 0.3, 0.6]), array([0.7814779 , 0.89403185, 0.81072332, 0.65995684, 0.69582527,\n",
      "       0.69325793, 0.79197053, 0.89440393, 0.87014437, 0.91468224,\n",
      "       0.7824453 , 0.82326239])) \n",
      "\n",
      "0.4 0.47809381580087645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.49492153865819516, 0.5083333333333332, array([0.56770456, 0.42424242, 0.5847769 , 0.57564178, 0.72828696,\n",
      "       0.69915773, 0.65136484, 0.14442013, 0.1502079 , 0.19978441,\n",
      "       0.8708717 , 0.34259913]), array([0.5, 0.6, 0.5, 0.4, 0.4, 0.4, 0.5, 0.7, 0.6, 0.6, 0.3, 0.6]), array([0.80008186, 0.86709332, 0.82341122, 0.67770502, 0.70095996,\n",
      "       0.70762018, 0.77902218, 0.89816193, 0.87833011, 0.91713797,\n",
      "       0.7918217 , 0.82664831])) \n",
      "\n",
      "0.5 0.48823751449356695\n",
      "(0.5047758027378862, 0.5083333333333332, array([0.58386993, 0.44379467, 0.58903171, 0.5884654 , 0.73517362,\n",
      "       0.71011167, 0.66320811, 0.1621955 , 0.15655676, 0.20485744,\n",
      "       0.87313433, 0.3469105 ]), array([0.5, 0.6, 0.5, 0.4, 0.4, 0.4, 0.5, 0.7, 0.6, 0.6, 0.3, 0.6]), array([0.80763506, 0.87260009, 0.82155083, 0.69467183, 0.70657836,\n",
      "       0.71796398, 0.78984968, 0.89890609, 0.87531627, 0.91594731,\n",
      "       0.79505879, 0.82460188])) \n",
      "\n",
      "0.6000000000000001 0.49432048663609424\n",
      "(0.5137311350717509, 0.5333333333333333, array([0.59541406, 0.45514789, 0.59225169, 0.59846547, 0.73941379,\n",
      "       0.71577899, 0.67133956, 0.17481481, 0.17566885, 0.21468354,\n",
      "       0.87680842, 0.35498652]), array([0.6, 0.6, 0.5, 0.4, 0.4, 0.4, 0.5, 0.7, 0.7, 0.7, 0.3, 0.6]), array([0.84112219, 0.87457211, 0.81868582, 0.70791784, 0.70988986,\n",
      "       0.72380563, 0.79587736, 0.89637595, 0.93923947, 0.94229052,\n",
      "       0.80134693, 0.82192291])) \n",
      "\n",
      "0.7000000000000001 0.4963200926462809\n",
      "(0.5197851189886463, 0.5416666666666666, array([0.59805362, 0.46924464, 0.58900264, 0.60113382, 0.74114478,\n",
      "       0.71920276, 0.67739796, 0.19782062, 0.18715904, 0.22087605,\n",
      "       0.87796162, 0.35842388]), array([0.6, 0.7, 0.5, 0.4, 0.4, 0.4, 0.5, 0.7, 0.7, 0.7, 0.3, 0.6]), array([0.83710374, 0.90143623, 0.81477898, 0.71465248, 0.71041078,\n",
      "       0.72741479, 0.80090043, 0.89317607, 0.92792826, 0.93778836,\n",
      "       0.80432356, 0.81764399])) \n",
      "\n",
      "0.8 0.49583596092783905\n",
      "(0.5211517806094753, 0.5583333333333335, array([0.59127162, 0.469762  , 0.58618726, 0.60211323, 0.74095706,\n",
      "       0.72053846, 0.67895564, 0.22391213, 0.18073633, 0.21956429,\n",
      "       0.87832638, 0.36149698]), array([0.6, 0.7, 0.5, 0.4, 0.4, 0.4, 0.5, 0.8, 0.7, 0.7, 0.3, 0.7]), array([0.83029469, 0.89886888, 0.81072332, 0.71837327, 0.70955499,\n",
      "       0.72964727, 0.80235154, 0.93164905, 0.91803096, 0.93202113,\n",
      "       0.80588629, 0.85462866])) \n",
      "\n",
      "0.9 0.49570599854987885\n",
      "(0.520772433607706, 0.5416666666666667, array([0.58593337, 0.4687738 , 0.58398265, 0.60157466, 0.73930733,\n",
      "       0.71945998, 0.6785477 , 0.23613193, 0.1765873 , 0.21522519,\n",
      "       0.87959612, 0.36414917]), array([0.6, 0.7, 0.5, 0.3, 0.4, 0.4, 0.5, 0.8, 0.7, 0.7, 0.2, 0.7]), array([0.8251972 , 0.89618991, 0.80730019, 0.67614228, 0.7067644 ,\n",
      "       0.72938681, 0.80201667, 0.92417026, 0.90735228, 0.92673761,\n",
      "       0.79944932, 0.84901027])) \n",
      "\n",
      "1.0 0.4943377041019861\n",
      "(0.5217870390537378, 0.5583333333333335, array([0.58350767, 0.46639283, 0.58247955, 0.60487214, 0.73661289,\n",
      "       0.71948443, 0.67720908, 0.25145518, 0.18346774, 0.2108389 ,\n",
      "       0.88044481, 0.36467925]), array([0.6, 0.7, 0.5, 0.3, 0.4, 0.4, 0.5, 0.9, 0.8, 0.7, 0.2, 0.7]), array([0.82222057, 0.89365977, 0.80439798, 0.68436523, 0.70296919,\n",
      "       0.72953565, 0.80101206, 0.95215062, 0.93972317, 0.92089597,\n",
      "       0.80238875, 0.84339187])) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w in np.linspace(0,1,11):\n",
    "    y_ensemble=w*y_pred_aus+(1-w)*y_of_val_preds_aus*masks_val_success.reshape((-1,1))\n",
    "    new_pred = ((y_ensemble >= 0.5) * 1)\n",
    "    f1_au=np.mean([f1_score(y_true=y_aus_val[masks_aus_val==1,i],y_pred=new_pred[masks_aus_val==1,i]) for i in range(y_ensemble.shape[1])])\n",
    "    print(w,f1_au)\n",
    "    print(f1_score_max(y_aus_val[masks_aus_val==1,:],y_ensemble[masks_aus_val==1,:],thresh=np.arange(0.1,1,0.1)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51160 ['image,valence,arousal,expression,aus', 'video45_1/00001.jpg', 'video45_1/00008.jpg', 'video45_1/00017.jpg', 'video45_1/00021.jpg']\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(DATA_DIR,'MTL_Challenge_test_set_release.txt'),'r') as f:\n",
    "    test_set_images=f.read().splitlines()\n",
    "print(len(test_set_images),test_set_images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdir=DATA_DIR /'test_results/MTL'\n",
    "if not os.path.exists(resdir):\n",
    "    os.makedirs(resdir)\n",
    "header = 'image,valence,arousal,expression,aus\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51159, 1290) 0\n"
     ]
    }
   ],
   "source": [
    "num_missed=0\n",
    "X_test=[]\n",
    "for imagename in test_set_images[1:]:\n",
    "    if imagename in filename2featuresTest:\n",
    "        if FEATURES_SCORES_AGGREGATION==FEATURES_ONLY:\n",
    "            X_test.append(filename2featuresTest[imagename][0])\n",
    "        elif FEATURES_SCORES_AGGREGATION==SCORES_ONLY:\n",
    "            X_test.append(filename2featuresTest[imagename][1])\n",
    "        else:\n",
    "            X_test.append(np.concatenate((filename2featuresTest[imagename][0],filename2featuresTest[imagename][1])))\n",
    "    else:\n",
    "        num_missed+=1\n",
    "    #elif (valence==-5 or arousal==-5) and valence!=arousal:\n",
    "    #    print(valence,arousal)\n",
    "X_test=np.array(X_test)\n",
    "print(X_test.shape,num_missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VA (51159,) (51159,) [0.7118035  0.49976918 0.55337983 0.50104845 0.42740974] [0.31474793 0.36706084 0.37494317 0.43688834 0.5564812 ]\n",
      "Expression (26876,) (51159,) [7 5 4 4 7]\n",
      "AUs (51159, 12) (51159, 12) [[0 0 0 1 1 1 1 0 0 0 1 0]\n",
      " [0 0 1 1 1 1 1 0 0 0 1 0]\n",
      " [0 0 0 1 1 1 1 0 0 0 1 0]\n",
      " [0 0 0 1 1 1 1 0 0 0 1 0]\n",
      " [0 0 1 1 1 1 1 0 0 0 1 0]]\n",
      "AUs (51159, 12) (51159, 12) [[0 0 0 1 1 1 1 0 0 0 1 0]\n",
      " [0 0 1 1 1 1 1 0 0 0 1 0]\n",
      " [0 0 0 1 1 1 1 0 0 0 1 0]\n",
      " [0 0 0 1 1 1 1 0 0 0 1 0]\n",
      " [0 0 1 1 1 1 1 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_expr,y_pred_va,y_pred_aus=mtl_model_new.predict(X_test)\n",
    "pred_V=y_pred_va[:,0]\n",
    "pred_A=y_pred_va[:,1]\n",
    "print('VA',pred_V.shape,pred_A.shape,pred_V[:5],pred_A[:5])\n",
    "\n",
    "y_pred=np.argmax(y_pred_expr,axis=1)\n",
    "print('Expression',y_expr_val.shape,y_pred.shape,y_pred[:5])\n",
    "\n",
    "thresholds=0.5\n",
    "aus_pred = ((y_pred_aus >= thresholds) * 1)\n",
    "print('AUs',y_pred_aus.shape,aus_pred.shape,aus_pred[:5])\n",
    "\n",
    "thresholds=np.array([0.6, 0.7, 0.5, 0.3, 0.4, 0.4, 0.5, 0.9, 0.8, 0.7, 0.2, 0.7])\n",
    "aus_pred_dynamic = ((y_pred_aus >= thresholds) * 1)\n",
    "print('AUs',y_pred_aus.shape,aus_pred_dynamic.shape,aus_pred_dynamic[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(resdir,'1_mtl_enet0_slice_aus_0.5.txt'), 'w') as f:\n",
    "#with open(os.path.join(resdir,'3_mtl_enet0_slice_aus_0.5_all.txt'), 'w') as f:\n",
    "    f.write(header)\n",
    "    for filename, v,a,expr,aus in zip(test_set_images[1:],pred_V,pred_A,y_pred,aus_pred):\n",
    "        s=','.join([filename,str(v),str(a),str(expr),*map(str,aus)])+'\\n'\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(resdir,'2_mtl_enet0_slice_aus_dyn.txt'), 'w') as f:\n",
    "    f.write(header)\n",
    "    for filename, v,a,expr,aus in zip(test_set_images[1:],pred_V,pred_A,y_pred,aus_pred_dynamic):\n",
    "        s=','.join([filename,str(v),str(a),str(expr),*map(str,aus)])+'\\n'\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenFace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51159, 35) (51159,) 0 47790 3369\n"
     ]
    }
   ],
   "source": [
    "num_missed=num_fails=0\n",
    "X_openface_test=[]\n",
    "mask_success=[]\n",
    "\n",
    "prev_videoname=''\n",
    "video_frames=None\n",
    "\n",
    "for imagename in test_set_images[1:]:\n",
    "    videoname,filename=imagename.split('/')\n",
    "    if videoname!=prev_videoname:\n",
    "        fpath=test_outdir / (videoname+'.csv')\n",
    "        if os.path.exists(fpath):\n",
    "            df = pd.read_csv(fpath)\n",
    "            success=(df.success==1).to_numpy()\n",
    "            df = df.drop(columns=['frame', 'face_id','timestamp', 'confidence', 'success'])\n",
    "            df=df.drop(columns=[c for c in df.columns if c.startswith('eye')])\n",
    "            df=df.drop(columns=[c for c in df.columns if c.startswith('gaze')])\n",
    "            #df=df.drop(columns=[c for c in df.columns if c.startswith('AU')])\n",
    "            df=df.drop(columns=[c for c in df.columns if c.startswith('pose')])\n",
    "            cur_features=df.to_numpy()\n",
    "\n",
    "            video_frames={f:i for i,f in enumerate(sorted(os.listdir(test_data_dir / videoname)))}\n",
    "            #print(videoname,cur_features.shape,len(video_frames))\n",
    "            prev_videoname=videoname\n",
    "\n",
    "    if video_frames is not None and filename in video_frames:\n",
    "        ind=video_frames[filename]\n",
    "        mask_success.append(success[ind])\n",
    "        X_openface_test.append(cur_features[ind])\n",
    "        if not success[ind]:\n",
    "            num_fails+=1\n",
    "    else:\n",
    "        num_missed+=1\n",
    "X_openface_test=np.array(X_openface_test)\n",
    "mask_success=np.array(mask_success)\n",
    "print(X_openface_test.shape,mask_success.shape,num_missed,mask_success.sum(),num_fails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_of_test_preds_expr=model_expr.predict(X_openface_test)\n",
    "w=0.6\n",
    "y_ensemble=w*y_pred_expr+(1-w)*y_of_test_preds_expr*mask_success.reshape((-1,1))\n",
    "y_pred=np.argmax(y_ensemble,axis=1)\n",
    "with open(os.path.join(resdir,'4_mtl_enet0_slice_aus_0.5_of.txt'), 'w') as f:\n",
    "    f.write(header)\n",
    "    for filename, v,a,expr,aus in zip(test_set_images[1:],pred_V,pred_A,y_pred,aus_pred):\n",
    "        s=','.join([filename,str(v),str(a),str(expr),*map(str,aus)])+'\\n'\n",
    "        f.write(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
